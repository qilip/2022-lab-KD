{"cells":[{"cell_type":"markdown","metadata":{"id":"Vvjuh7IpQKQT"},"source":["# Baseline\n","\n","* ERFNet 기본 네트워크"]},{"cell_type":"markdown","metadata":{"id":"DOJ079ztXDoy"},"source":["## 1. 사전 설정"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19346,"status":"ok","timestamp":1668931199664,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"QHoceWzXPw-E","outputId":"a042089d-2796-4ad8-85f9-2917ceb6d6e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Google Drive 마운트\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"EvdmPAHwx4Hv"},"source":["## Load cityscapes dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1932,"status":"ok","timestamp":1668931201594,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"5c4Y2qVhw4Iy"},"outputs":[],"source":["import numpy as np\n","import os\n","\n","from PIL import Image\n","\n","from torch.utils.data import Dataset\n","\n","EXTENSIONS = ['.jpg', '.png']\n","\n","def load_image(file):\n","    return Image.open(file)\n","\n","def is_image(filename):\n","    return any(filename.endswith(ext) for ext in EXTENSIONS)\n","\n","def is_label(filename):\n","    return filename.endswith(\"_labelTrainIds.png\")\n","\n","def image_path(root, basename, extension):\n","    return os.path.join(root, f'{basename}{extension}')\n","\n","def image_path_city(root, name):\n","    return os.path.join(root, f'{name}')\n","\n","def image_basename(filename):\n","    return os.path.basename(os.path.splitext(filename)[0])\n","\n","class VOC12(Dataset):\n","\n","    def __init__(self, root, input_transform=None, target_transform=None):\n","        self.images_root = os.path.join(root, 'images')\n","        self.labels_root = os.path.join(root, 'labels')\n","\n","        self.filenames = [image_basename(f)\n","            for f in os.listdir(self.labels_root) if is_image(f)]\n","        self.filenames.sort()\n","\n","        self.input_transform = input_transform\n","        self.target_transform = target_transform\n","\n","    def __getitem__(self, index):\n","        filename = self.filenames[index]\n","\n","        with open(image_path(self.images_root, filename, '.jpg'), 'rb') as f:\n","            image = load_image(f).convert('RGB')\n","        with open(image_path(self.labels_root, filename, '.png'), 'rb') as f:\n","            label = load_image(f).convert('P')\n","\n","        if self.input_transform is not None:\n","            image = self.input_transform(image)\n","        if self.target_transform is not None:\n","            label = self.target_transform(label)\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.filenames)\n","\n","\n","\n","\n","class cityscapes(Dataset):\n","\n","    def __init__(self, root, co_transform=None, subset='train'):\n","        self.images_root = os.path.join(root, 'leftImg8bit/')\n","        self.labels_root = os.path.join(root, 'gtFine/')\n","        \n","        self.images_root += subset\n","        self.labels_root += subset\n","\n","        print (self.images_root)\n","        #self.filenames = [image_basename(f) for f in os.listdir(self.images_root) if is_image(f)]\n","        self.filenames = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(self.images_root)) for f in fn if is_image(f)]\n","        self.filenames.sort()\n","\n","        #[os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\".\")) for f in fn]\n","        #self.filenamesGt = [image_basename(f) for f in os.listdir(self.labels_root) if is_image(f)]\n","        self.filenamesGt = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(self.labels_root)) for f in fn if is_label(f)]\n","        self.filenamesGt.sort()\n","\n","        self.co_transform = co_transform # ADDED THIS\n","\n","\n","    def __getitem__(self, index):\n","        filename = self.filenames[index]\n","        filenameGt = self.filenamesGt[index]\n","\n","        with open(image_path_city(self.images_root, filename), 'rb') as f:\n","            image = load_image(f).convert('RGB')\n","        with open(image_path_city(self.labels_root, filenameGt), 'rb') as f:\n","            label = load_image(f).convert('P')\n","\n","        if self.co_transform is not None:\n","            image, label = self.co_transform(image, label)\n","\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.filenames)"]},{"cell_type":"markdown","metadata":{"id":"5mMl1PV7AfFh"},"source":["## ERFNet Model Common module"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668931201594,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"2toyughnAlL5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","\n","class DownsamplerBlock (nn.Module):\n","    def __init__(self, ninput, noutput):\n","        super().__init__()\n","\n","        self.conv = nn.Conv2d(ninput, noutput-ninput, (3, 3), stride=2, padding=1, bias=True)\n","        self.pool = nn.MaxPool2d(2, stride=2)\n","        self.bn = nn.BatchNorm2d(noutput, eps=1e-3)\n","\n","    def forward(self, input):\n","        output = torch.cat([self.conv(input), self.pool(input)], 1)\n","        output = self.bn(output)\n","        return F.relu(output)\n","\n","class UpsamplerBlock (nn.Module):\n","    def __init__(self, ninput, noutput):\n","        super().__init__()\n","        self.conv = nn.ConvTranspose2d(ninput, noutput, 3, stride=2, padding=1, output_padding=1, bias=True)\n","        self.bn = nn.BatchNorm2d(noutput, eps=1e-3)\n","\n","    def forward(self, input):\n","        output = self.conv(input)\n","        output = self.bn(output)\n","        return F.relu(output)"]},{"cell_type":"markdown","metadata":{"id":"GfpwyVUI_P1k"},"source":["## ERFNet Model [Teacher]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668931201595,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"xd_D4TCa_T_6"},"outputs":[],"source":["# ERFNet full model definition for Pytorch\n","# Sept 2017\n","# Eduardo Romera\n","#######################\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","\n","class non_bottleneck (nn.Module):\n","    def __init__(self, chann, dropprob, dilated):        \n","        super().__init__()\n","\n","        self.conv3_1 = nn.Conv2d(chann, chann, (3,3), stride=1, padding=(1,1), bias=True)\n","\n","        # self.conv1x3_1 = nn.Conv2d(chann, chann, (1,3), stride=1, padding=(0,1), bias=True)\n","\n","        self.bn1 = nn.BatchNorm2d(chann, eps=1e-03)\n","\n","        self.conv3_2 = nn.Conv2d(chann, chann, (3, 3), stride=1, padding=(1*dilated,1*dilated), bias=True, dilation = (dilated,dilated))\n","\n","        # self.conv1x3_2 = nn.Conv2d(chann, chann, (1,3), stride=1, padding=(0,1*dilated), bias=True, dilation = (1, dilated))\n","\n","        self.bn2 = nn.BatchNorm2d(chann, eps=1e-03)\n","\n","        self.dropout = nn.Dropout2d(dropprob)\n","        \n","\n","    def forward(self, input):\n","\n","        output = self.conv3_1(input)\n","        # output = F.relu(output)\n","        # output = self.conv1x3_1(output)\n","        output = self.bn1(output)\n","        output = F.relu(output)\n","\n","        output = self.conv3_2(output)\n","        # output = F.relu(output)\n","        # output = self.conv1x3_2(output)\n","        output = self.bn2(output)\n","\n","        if (self.dropout.p != 0):\n","            output = self.dropout(output)\n","        \n","        return F.relu(output+input)    #+input = identity (residual connection)\n","\n","\n","class TEncoder(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.initial_block = DownsamplerBlock(3,16)\n","\n","        self.layers = nn.ModuleList()\n","\n","        self.layers.append(DownsamplerBlock(16,64))\n","\n","        for x in range(0, 5):    #5 times\n","           self.layers.append(non_bottleneck(64, 0.03, 1)) \n","\n","        self.layers.append(DownsamplerBlock(64,128))\n","\n","        for x in range(0, 2):    #2 times\n","            self.layers.append(non_bottleneck(128, 0.3, 2))\n","            self.layers.append(non_bottleneck(128, 0.3, 4))\n","            self.layers.append(non_bottleneck(128, 0.3, 8))\n","            self.layers.append(non_bottleneck(128, 0.3, 16))\n","\n","        #Only in encoder mode:\n","        self.output_conv = nn.Conv2d(128, num_classes, 1, stride=1, padding=0, bias=True)\n","\n","    def forward(self, input, predict=False):\n","        output = self.initial_block(input)\n","\n","        for layer in self.layers:\n","            output = layer(output)\n","\n","        if predict:\n","            output = self.output_conv(output)\n","\n","        return output\n","\n","class TDecoder (nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        self.layers = nn.ModuleList()\n","\n","        self.layers.append(UpsamplerBlock(128,64))\n","        self.layers.append(non_bottleneck(64, 0, 1))\n","        self.layers.append(non_bottleneck(64, 0, 1))\n","\n","        self.layers.append(UpsamplerBlock(64,16))\n","        self.layers.append(non_bottleneck(16, 0, 1))\n","        self.layers.append(non_bottleneck(16, 0, 1))\n","\n","        self.output_conv = nn.ConvTranspose2d( 16, num_classes, 2, stride=2, padding=0, output_padding=0, bias=True)\n","\n","    def forward(self, input):\n","        output = input\n","\n","        for layer in self.layers:\n","            output = layer(output)\n","\n","        output = self.output_conv(output)\n","\n","        return output\n","\n","#ERFNet Teacher\n","class TNet(nn.Module):\n","    def __init__(self, num_classes, encoder=None):  #use encoder to pass pretrained encoder\n","        super().__init__()\n","\n","        if (encoder == None):\n","            self.encoder = TEncoder(num_classes)\n","        else:\n","            self.encoder = encoder\n","        self.decoder = TDecoder(num_classes)\n","\n","    def forward(self, input, only_encode=False):\n","        if only_encode:\n","            return self.encoder.forward(input, predict=True)\n","        else:\n","            output = self.encoder(input)    #predict=False by default\n","            return self.decoder.forward(output)"]},{"cell_type":"markdown","metadata":{"id":"7dIBPw72yGdh"},"source":["## ERFNet model definition [Student]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668931201595,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"rIRGLl2HQKCB"},"outputs":[],"source":["# ERFNet full model definition for Pytorch\n","# Sept 2017\n","# Eduardo Romera\n","#######################\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","\n","class non_bottleneck_1d (nn.Module):\n","    def __init__(self, chann, dropprob, dilated):        \n","        super().__init__()\n","\n","        self.conv3x1_1 = nn.Conv2d(chann, chann, (3, 1), stride=1, padding=(1,0), bias=True)\n","\n","        self.conv1x3_1 = nn.Conv2d(chann, chann, (1,3), stride=1, padding=(0,1), bias=True)\n","\n","        self.bn1 = nn.BatchNorm2d(chann, eps=1e-03)\n","\n","        self.conv3x1_2 = nn.Conv2d(chann, chann, (3, 1), stride=1, padding=(1*dilated,0), bias=True, dilation = (dilated,1))\n","\n","        self.conv1x3_2 = nn.Conv2d(chann, chann, (1,3), stride=1, padding=(0,1*dilated), bias=True, dilation = (1, dilated))\n","\n","        self.bn2 = nn.BatchNorm2d(chann, eps=1e-03)\n","\n","        self.dropout = nn.Dropout2d(dropprob)\n","        \n","\n","    def forward(self, input):\n","\n","        output = self.conv3x1_1(input)\n","        output = F.relu(output)\n","        output = self.conv1x3_1(output)\n","        output = self.bn1(output)\n","        output = F.relu(output)\n","\n","        output = self.conv3x1_2(output)\n","        output = F.relu(output)\n","        output = self.conv1x3_2(output)\n","        output = self.bn2(output)\n","\n","        if (self.dropout.p != 0):\n","            output = self.dropout(output)\n","        \n","        return F.relu(output+input)    #+input = identity (residual connection)\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.initial_block = DownsamplerBlock(3,16)\n","\n","        self.layers = nn.ModuleList()\n","\n","        self.layers.append(DownsamplerBlock(16,64))\n","\n","        for x in range(0, 1):    #1 times\n","           self.layers.append(non_bottleneck_1d(64, 0.03, 1)) \n","\n","        self.layers.append(DownsamplerBlock(64,128))\n","\n","        for x in range(0, 1):    #1 times\n","            self.layers.append(non_bottleneck_1d(128, 0.3, 2))\n","            self.layers.append(non_bottleneck_1d(128, 0.3, 4))\n","            self.layers.append(non_bottleneck_1d(128, 0.3, 8))\n","            self.layers.append(non_bottleneck_1d(128, 0.3, 16))\n","\n","        #Only in encoder mode:\n","        self.output_conv = nn.Conv2d(128, num_classes, 1, stride=1, padding=0, bias=True)\n","\n","    def forward(self, input, predict=False):\n","        output = self.initial_block(input)\n","\n","        for layer in self.layers:\n","            output = layer(output)\n","\n","        if predict:\n","            output = self.output_conv(output)\n","\n","        return output\n","\n","class Decoder (nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        self.layers = nn.ModuleList()\n","\n","        self.layers.append(UpsamplerBlock(128,64))\n","        self.layers.append(non_bottleneck_1d(64, 0, 1))\n","        # self.layers.append(non_bottleneck_1d(64, 0, 1))\n","\n","        self.layers.append(UpsamplerBlock(64,16))\n","        self.layers.append(non_bottleneck_1d(16, 0, 1))\n","        # self.layers.append(non_bottleneck_1d(16, 0, 1))\n","\n","        self.output_conv = nn.ConvTranspose2d( 16, num_classes, 2, stride=2, padding=0, output_padding=0, bias=True)\n","\n","    def forward(self, input):\n","        output = input\n","\n","        for layer in self.layers:\n","            output = layer(output)\n","\n","        output = self.output_conv(output)\n","\n","        return output\n","\n","#ERFNet\n","class Net(nn.Module):\n","    def __init__(self, num_classes, encoder=None):  #use encoder to pass pretrained encoder\n","        super().__init__()\n","\n","        if (encoder == None):\n","            self.encoder = Encoder(num_classes)\n","        else:\n","            self.encoder = encoder\n","        self.decoder = Decoder(num_classes)\n","\n","    def forward(self, input, only_encode=False):\n","        if only_encode:\n","            return self.encoder.forward(input, predict=True)\n","        else:\n","            output = self.encoder(input)    #predict=False by default\n","            return self.decoder.forward(output)"]},{"cell_type":"markdown","metadata":{"id":"V4qUd0BYzy3p"},"source":["## Calculate IoU on each epoch during training"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668931201595,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"mtvDwB-syAJD"},"outputs":[],"source":["import torch\n","\n","class iouEval:\n","\n","    def __init__(self, nClasses, ignoreIndex=19):\n","        self.nClasses = nClasses\n","        self.ignoreIndex = ignoreIndex if nClasses>ignoreIndex else -1 #if ignoreIndex is larger than nClasses, consider no ignoreIndex\n","        self.reset()\n","\n","    def reset (self):\n","        classes = self.nClasses if self.ignoreIndex==-1 else self.nClasses-1\n","        self.tp = torch.zeros(classes).double()\n","        self.fp = torch.zeros(classes).double()\n","        self.fn = torch.zeros(classes).double()        \n","\n","    def addBatch(self, x, y):   #x=preds, y=targets\n","        #sizes should be \"batch_size x nClasses x H x W\"\n","\n","        if (x.is_cuda or y.is_cuda):\n","            x = x.cuda()\n","            y = y.cuda()\n","\n","        #if size is \"batch_size x 1 x H x W\" scatter to onehot\n","        if (x.size(1) == 1):\n","            x_onehot = torch.zeros(x.size(0), self.nClasses, x.size(2), x.size(3))  \n","            if x.is_cuda:\n","                x_onehot = x_onehot.cuda()\n","            x_onehot.scatter_(1, x, 1).float()\n","        else:\n","            x_onehot = x.float()\n","\n","        if (y.size(1) == 1):\n","            y_onehot = torch.zeros(y.size(0), self.nClasses, y.size(2), y.size(3))\n","            if y.is_cuda:\n","                y_onehot = y_onehot.cuda()\n","            y_onehot.scatter_(1, y, 1).float()\n","        else:\n","            y_onehot = y.float()\n","\n","        if (self.ignoreIndex != -1): \n","            ignores = y_onehot[:,self.ignoreIndex].unsqueeze(1)\n","            x_onehot = x_onehot[:, :self.ignoreIndex]\n","            y_onehot = y_onehot[:, :self.ignoreIndex]\n","        else:\n","            ignores=0\n","\n","        tpmult = x_onehot * y_onehot    #times prediction and gt coincide is 1\n","        tp = torch.sum(torch.sum(torch.sum(tpmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze()\n","        fpmult = x_onehot * (1-y_onehot-ignores) #times prediction says its that class and gt says its not (subtracting cases when its ignore label!)\n","        fp = torch.sum(torch.sum(torch.sum(fpmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze()\n","        fnmult = (1-x_onehot) * (y_onehot) #times prediction says its not that class and gt says it is\n","        fn = torch.sum(torch.sum(torch.sum(fnmult, dim=0, keepdim=True), dim=2, keepdim=True), dim=3, keepdim=True).squeeze() \n","\n","        self.tp += tp.double().cpu()\n","        self.fp += fp.double().cpu()\n","        self.fn += fn.double().cpu()\n","\n","    def getIoU(self):\n","        num = self.tp\n","        den = self.tp + self.fp + self.fn + 1e-15\n","        iou = num / den\n","        return torch.mean(iou), iou     #returns \"iou mean\", \"iou per class\"\n","\n","# Class for colors\n","class colors:\n","    RED       = '\\033[31;1m'\n","    GREEN     = '\\033[32;1m'\n","    YELLOW    = '\\033[33;1m'\n","    BLUE      = '\\033[34;1m'\n","    MAGENTA   = '\\033[35;1m'\n","    CYAN      = '\\033[36;1m'\n","    BOLD      = '\\033[1m'\n","    UNDERLINE = '\\033[4m'\n","    ENDC      = '\\033[0m'\n","\n","# Colored value output if colorized flag is activated.\n","def getColorEntry(val):\n","    if not isinstance(val, float):\n","        return colors.ENDC\n","    if (val < .20):\n","        return colors.RED\n","    elif (val < .40):\n","        return colors.YELLOW\n","    elif (val < .60):\n","        return colors.BLUE\n","    elif (val < .80):\n","        return colors.CYAN\n","    else:\n","        return colors.GREEN"]},{"cell_type":"markdown","metadata":{"id":"4t1QcUG_1FBi"},"source":["## Transform"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668931201596,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"},"user_tz":-540},"id":"ke6O9-DT1FZq"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","from PIL import Image\n","\n","def colormap_cityscapes(n):\n","    cmap=np.zeros([n, 3]).astype(np.uint8)\n","    cmap[0,:] = np.array([128, 64,128])\n","    cmap[1,:] = np.array([244, 35,232])\n","    cmap[2,:] = np.array([ 70, 70, 70])\n","    cmap[3,:] = np.array([ 102,102,156])\n","    cmap[4,:] = np.array([ 190,153,153])\n","    cmap[5,:] = np.array([ 153,153,153])\n","\n","    cmap[6,:] = np.array([ 250,170, 30])\n","    cmap[7,:] = np.array([ 220,220,  0])\n","    cmap[8,:] = np.array([ 107,142, 35])\n","    cmap[9,:] = np.array([ 152,251,152])\n","    cmap[10,:] = np.array([ 70,130,180])\n","\n","    cmap[11,:] = np.array([ 220, 20, 60])\n","    cmap[12,:] = np.array([ 255,  0,  0])\n","    cmap[13,:] = np.array([ 0,  0,142])\n","    cmap[14,:] = np.array([  0,  0, 70])\n","    cmap[15,:] = np.array([  0, 60,100])\n","\n","    cmap[16,:] = np.array([  0, 80,100])\n","    cmap[17,:] = np.array([  0,  0,230])\n","    cmap[18,:] = np.array([ 119, 11, 32])\n","    cmap[19,:] = np.array([ 0,  0,  0])\n","    \n","    return cmap\n","\n","\n","def colormap(n):\n","    cmap=np.zeros([n, 3]).astype(np.uint8)\n","\n","    for i in np.arange(n):\n","        r, g, b = np.zeros(3)\n","\n","        for j in np.arange(8):\n","            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))\n","            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))\n","            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2))\n","\n","        cmap[i,:] = np.array([r, g, b])\n","\n","    return cmap\n","\n","class Relabel:\n","\n","    def __init__(self, olabel, nlabel):\n","        self.olabel = olabel\n","        self.nlabel = nlabel\n","\n","    def __call__(self, tensor):\n","        assert (isinstance(tensor, torch.LongTensor) or isinstance(tensor, torch.ByteTensor)) , 'tensor needs to be LongTensor'\n","        tensor[tensor == self.olabel] = self.nlabel\n","        return tensor\n","\n","\n","class ToLabel:\n","\n","    def __call__(self, image):\n","        return torch.from_numpy(np.array(image)).long().unsqueeze(0)\n","\n","\n","class Colorize:\n","\n","    def __init__(self, n=22):\n","        #self.cmap = colormap(256)\n","        self.cmap = colormap_cityscapes(256)\n","        self.cmap[n] = self.cmap[-1]\n","        self.cmap = torch.from_numpy(self.cmap[:n])\n","\n","    def __call__(self, gray_image):\n","        size = gray_image.size()\n","        #print(size)\n","        color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)\n","        #color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)\n","\n","        #for label in range(1, len(self.cmap)):\n","        for label in range(0, len(self.cmap)):\n","            mask = gray_image[0] == label\n","            #mask = gray_image == label\n","\n","            color_image[0][mask] = self.cmap[label][0]\n","            color_image[1][mask] = self.cmap[label][1]\n","            color_image[2][mask] = self.cmap[label][2]\n","\n","        return color_image"]},{"cell_type":"markdown","metadata":{"id":"VWEiMU1a0w5W"},"source":["## Main"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3CwiOPP1FwS","executionInfo":{"status":"ok","timestamp":1668949571970,"user_tz":-540,"elapsed":3230745,"user":{"displayName":"SangMin Shin","userId":"04005229734820315323"}},"outputId":"f74396d2-4d42-428c-8c1d-a58a9368fa7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Teacher Model and weights LOADED successfully\n","========== ENCODER TRAINING ===========\n","/content/gdrive/MyDrive/Colab Notebooks/cityscapes/leftImg8bit/train\n","/content/gdrive/MyDrive/Colab Notebooks/cityscapes/leftImg8bit/val\n","<class '__main__.MainLoss'>\n","----- TRAINING - EPOCH 1 -----\n","LEARNING RATE:  0.0005\n","loss: 2.715 (epoch: 1, step: 0) // Avg time/img: 2.4804 s\n","loss: 1.321 (epoch: 1, step: 50) // Avg time/img: 0.1267 s\n","loss: 1.185 (epoch: 1, step: 100) // Avg time/img: 0.1062 s\n","loss: 1.119 (epoch: 1, step: 150) // Avg time/img: 0.0985 s\n","loss: 1.083 (epoch: 1, step: 200) // Avg time/img: 0.0945 s\n","----- VALIDATING - EPOCH 1 -----\n","VAL loss: 1.13 (epoch: 1, step: 0) // Avg time/img: 0.0400 s\n","VAL loss: 1.095 (epoch: 1, step: 50) // Avg time/img: 0.0310 s\n","VAL loss: 1.084 (epoch: 1, step: 100) // Avg time/img: 0.0307 s\n","VAL loss: 1.031 (epoch: 1, step: 150) // Avg time/img: 0.0312 s\n","EPOCH IoU on VAL set:  \u001b[0m17.24\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 1)\n","----- TRAINING - EPOCH 2 -----\n","LEARNING RATE:  0.000492493711467861\n","loss: 1.024 (epoch: 2, step: 0) // Avg time/img: 0.1057 s\n","loss: 0.9131 (epoch: 2, step: 50) // Avg time/img: 0.0863 s\n","loss: 0.8967 (epoch: 2, step: 100) // Avg time/img: 0.0872 s\n","loss: 0.8889 (epoch: 2, step: 150) // Avg time/img: 0.0876 s\n","loss: 0.8816 (epoch: 2, step: 200) // Avg time/img: 0.0883 s\n","----- VALIDATING - EPOCH 2 -----\n","VAL loss: 0.9874 (epoch: 2, step: 0) // Avg time/img: 0.0425 s\n","VAL loss: 1.039 (epoch: 2, step: 50) // Avg time/img: 0.0347 s\n","VAL loss: 1.031 (epoch: 2, step: 100) // Avg time/img: 0.0341 s\n","VAL loss: 0.9681 (epoch: 2, step: 150) // Avg time/img: 0.0337 s\n","EPOCH IoU on VAL set:  \u001b[0m17.09\u001b[0m %\n","----- TRAINING - EPOCH 3 -----\n","LEARNING RATE:  0.0004849746889841331\n","loss: 0.7583 (epoch: 3, step: 0) // Avg time/img: 0.0910 s\n","loss: 0.8317 (epoch: 3, step: 50) // Avg time/img: 0.0885 s\n","loss: 0.8289 (epoch: 3, step: 100) // Avg time/img: 0.0888 s\n","loss: 0.8294 (epoch: 3, step: 150) // Avg time/img: 0.0886 s\n","loss: 0.8305 (epoch: 3, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 3 -----\n","VAL loss: 1.05 (epoch: 3, step: 0) // Avg time/img: 0.0266 s\n","VAL loss: 1.045 (epoch: 3, step: 50) // Avg time/img: 0.0327 s\n","VAL loss: 1.02 (epoch: 3, step: 100) // Avg time/img: 0.0324 s\n","VAL loss: 0.9559 (epoch: 3, step: 150) // Avg time/img: 0.0322 s\n","EPOCH IoU on VAL set:  \u001b[0m20.60\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 3)\n","----- TRAINING - EPOCH 4 -----\n","LEARNING RATE:  0.00047744269081074987\n","loss: 0.9273 (epoch: 4, step: 0) // Avg time/img: 0.0981 s\n","loss: 0.8223 (epoch: 4, step: 50) // Avg time/img: 0.0885 s\n","loss: 0.8115 (epoch: 4, step: 100) // Avg time/img: 0.0885 s\n","loss: 0.8076 (epoch: 4, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.8007 (epoch: 4, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 4 -----\n","VAL loss: 0.8544 (epoch: 4, step: 0) // Avg time/img: 0.0336 s\n","VAL loss: 0.9431 (epoch: 4, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.9353 (epoch: 4, step: 100) // Avg time/img: 0.0326 s\n","VAL loss: 0.8859 (epoch: 4, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m22.29\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 4)\n","----- TRAINING - EPOCH 5 -----\n","LEARNING RATE:  0.00046989746629436113\n","loss: 0.8262 (epoch: 5, step: 0) // Avg time/img: 0.0908 s\n","loss: 0.7616 (epoch: 5, step: 50) // Avg time/img: 0.0897 s\n","loss: 0.7645 (epoch: 5, step: 100) // Avg time/img: 0.0895 s\n","loss: 0.7656 (epoch: 5, step: 150) // Avg time/img: 0.0891 s\n","loss: 0.7656 (epoch: 5, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 5 -----\n","VAL loss: 0.9153 (epoch: 5, step: 0) // Avg time/img: 0.0322 s\n","VAL loss: 0.9305 (epoch: 5, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.932 (epoch: 5, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.8809 (epoch: 5, step: 150) // Avg time/img: 0.0325 s\n","EPOCH IoU on VAL set:  \u001b[0m22.71\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 5)\n","----- TRAINING - EPOCH 6 -----\n","LEARNING RATE:  0.0004623387553722673\n","loss: 0.7325 (epoch: 6, step: 0) // Avg time/img: 0.1097 s\n","loss: 0.7706 (epoch: 6, step: 50) // Avg time/img: 0.0900 s\n","loss: 0.754 (epoch: 6, step: 100) // Avg time/img: 0.0890 s\n","loss: 0.7517 (epoch: 6, step: 150) // Avg time/img: 0.0886 s\n","loss: 0.7494 (epoch: 6, step: 200) // Avg time/img: 0.0884 s\n","----- VALIDATING - EPOCH 6 -----\n","VAL loss: 0.8284 (epoch: 6, step: 0) // Avg time/img: 0.0349 s\n","VAL loss: 0.9099 (epoch: 6, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.9031 (epoch: 6, step: 100) // Avg time/img: 0.0330 s\n","VAL loss: 0.8573 (epoch: 6, step: 150) // Avg time/img: 0.0329 s\n","EPOCH IoU on VAL set:  \u001b[0m24.38\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 6)\n","----- TRAINING - EPOCH 7 -----\n","LEARNING RATE:  0.00045476628804148113\n","loss: 0.7524 (epoch: 7, step: 0) // Avg time/img: 0.0941 s\n","loss: 0.7427 (epoch: 7, step: 50) // Avg time/img: 0.0894 s\n","loss: 0.7444 (epoch: 7, step: 100) // Avg time/img: 0.0888 s\n","loss: 0.7443 (epoch: 7, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.7383 (epoch: 7, step: 200) // Avg time/img: 0.0883 s\n","----- VALIDATING - EPOCH 7 -----\n","VAL loss: 0.771 (epoch: 7, step: 0) // Avg time/img: 0.0341 s\n","VAL loss: 0.8878 (epoch: 7, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.8856 (epoch: 7, step: 100) // Avg time/img: 0.0319 s\n","VAL loss: 0.8433 (epoch: 7, step: 150) // Avg time/img: 0.0320 s\n","EPOCH IoU on VAL set:  \u001b[0m26.91\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 7)\n","----- TRAINING - EPOCH 8 -----\n","LEARNING RATE:  0.00044717978378742816\n","loss: 0.6791 (epoch: 8, step: 0) // Avg time/img: 0.0940 s\n","loss: 0.7193 (epoch: 8, step: 50) // Avg time/img: 0.0911 s\n","loss: 0.7242 (epoch: 8, step: 100) // Avg time/img: 0.0900 s\n","loss: 0.7294 (epoch: 8, step: 150) // Avg time/img: 0.0892 s\n","loss: 0.7284 (epoch: 8, step: 200) // Avg time/img: 0.0889 s\n","----- VALIDATING - EPOCH 8 -----\n","VAL loss: 0.8787 (epoch: 8, step: 0) // Avg time/img: 0.0356 s\n","VAL loss: 0.8606 (epoch: 8, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.8524 (epoch: 8, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.8088 (epoch: 8, step: 150) // Avg time/img: 0.0322 s\n","EPOCH IoU on VAL set:  \u001b[0m28.09\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 8)\n","----- TRAINING - EPOCH 9 -----\n","LEARNING RATE:  0.00043957895096839955\n","loss: 0.6808 (epoch: 9, step: 0) // Avg time/img: 0.0940 s\n","loss: 0.718 (epoch: 9, step: 50) // Avg time/img: 0.0896 s\n","loss: 0.7267 (epoch: 9, step: 100) // Avg time/img: 0.0887 s\n","loss: 0.7228 (epoch: 9, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.7181 (epoch: 9, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 9 -----\n","VAL loss: 1.007 (epoch: 9, step: 0) // Avg time/img: 0.0313 s\n","VAL loss: 0.93 (epoch: 9, step: 50) // Avg time/img: 0.0324 s\n","VAL loss: 0.9187 (epoch: 9, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.8613 (epoch: 9, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m26.05\u001b[0m %\n","----- TRAINING - EPOCH 10 -----\n","LEARNING RATE:  0.00043196348615140955\n","loss: 0.6942 (epoch: 10, step: 0) // Avg time/img: 0.0924 s\n","loss: 0.7048 (epoch: 10, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.7107 (epoch: 10, step: 100) // Avg time/img: 0.0898 s\n","loss: 0.7172 (epoch: 10, step: 150) // Avg time/img: 0.0894 s\n","loss: 0.7165 (epoch: 10, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 10 -----\n","VAL loss: 0.8221 (epoch: 10, step: 0) // Avg time/img: 0.0344 s\n","VAL loss: 0.9281 (epoch: 10, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.9367 (epoch: 10, step: 100) // Avg time/img: 0.0325 s\n","VAL loss: 0.8745 (epoch: 10, step: 150) // Avg time/img: 0.0324 s\n","EPOCH IoU on VAL set:  \u001b[0m25.52\u001b[0m %\n","----- TRAINING - EPOCH 11 -----\n","LEARNING RATE:  0.00042433307339459345\n","loss: 0.6905 (epoch: 11, step: 0) // Avg time/img: 0.0902 s\n","loss: 0.7148 (epoch: 11, step: 50) // Avg time/img: 0.0889 s\n","loss: 0.7129 (epoch: 11, step: 100) // Avg time/img: 0.0887 s\n","loss: 0.7073 (epoch: 11, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.7057 (epoch: 11, step: 200) // Avg time/img: 0.0884 s\n","----- VALIDATING - EPOCH 11 -----\n","VAL loss: 0.8783 (epoch: 11, step: 0) // Avg time/img: 0.0288 s\n","VAL loss: 0.875 (epoch: 11, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.8655 (epoch: 11, step: 100) // Avg time/img: 0.0333 s\n","VAL loss: 0.8238 (epoch: 11, step: 150) // Avg time/img: 0.0329 s\n","EPOCH IoU on VAL set:  \u001b[0m26.35\u001b[0m %\n","----- TRAINING - EPOCH 12 -----\n","LEARNING RATE:  0.0004166873834706844\n","loss: 0.6941 (epoch: 12, step: 0) // Avg time/img: 0.0954 s\n","loss: 0.6927 (epoch: 12, step: 50) // Avg time/img: 0.0891 s\n","loss: 0.6981 (epoch: 12, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6949 (epoch: 12, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.6958 (epoch: 12, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 12 -----\n","VAL loss: 0.8214 (epoch: 12, step: 0) // Avg time/img: 0.0351 s\n","VAL loss: 0.8888 (epoch: 12, step: 50) // Avg time/img: 0.0321 s\n","VAL loss: 0.8775 (epoch: 12, step: 100) // Avg time/img: 0.0320 s\n","VAL loss: 0.8317 (epoch: 12, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m28.53\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 12)\n","----- TRAINING - EPOCH 13 -----\n","LEARNING RATE:  0.00040902607302542923\n","loss: 0.6977 (epoch: 13, step: 0) // Avg time/img: 0.0875 s\n","loss: 0.7087 (epoch: 13, step: 50) // Avg time/img: 0.0912 s\n","loss: 0.7005 (epoch: 13, step: 100) // Avg time/img: 0.0902 s\n","loss: 0.6993 (epoch: 13, step: 150) // Avg time/img: 0.0895 s\n","loss: 0.6942 (epoch: 13, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 13 -----\n","VAL loss: 0.7354 (epoch: 13, step: 0) // Avg time/img: 0.0358 s\n","VAL loss: 0.8191 (epoch: 13, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.8081 (epoch: 13, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.7699 (epoch: 13, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m29.92\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 13)\n","----- TRAINING - EPOCH 14 -----\n","LEARNING RATE:  0.0004013487836640184\n","loss: 0.6675 (epoch: 14, step: 0) // Avg time/img: 0.0835 s\n","loss: 0.6811 (epoch: 14, step: 50) // Avg time/img: 0.0890 s\n","loss: 0.6918 (epoch: 14, step: 100) // Avg time/img: 0.0887 s\n","loss: 0.6915 (epoch: 14, step: 150) // Avg time/img: 0.0891 s\n","loss: 0.6879 (epoch: 14, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 14 -----\n","VAL loss: 0.755 (epoch: 14, step: 0) // Avg time/img: 0.0281 s\n","VAL loss: 0.8322 (epoch: 14, step: 50) // Avg time/img: 0.0329 s\n","VAL loss: 0.8113 (epoch: 14, step: 100) // Avg time/img: 0.0326 s\n","VAL loss: 0.7726 (epoch: 14, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m30.83\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 14)\n","----- TRAINING - EPOCH 15 -----\n","LEARNING RATE:  0.0003936551409577103\n","loss: 0.697 (epoch: 15, step: 0) // Avg time/img: 0.0933 s\n","loss: 0.697 (epoch: 15, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.6867 (epoch: 15, step: 100) // Avg time/img: 0.0893 s\n","loss: 0.6895 (epoch: 15, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.6884 (epoch: 15, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 15 -----\n","VAL loss: 0.7124 (epoch: 15, step: 0) // Avg time/img: 0.0341 s\n","VAL loss: 0.7964 (epoch: 15, step: 50) // Avg time/img: 0.0337 s\n","VAL loss: 0.7867 (epoch: 15, step: 100) // Avg time/img: 0.0335 s\n","VAL loss: 0.7547 (epoch: 15, step: 150) // Avg time/img: 0.0333 s\n","EPOCH IoU on VAL set:  \u001b[0m31.98\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 15)\n","----- TRAINING - EPOCH 16 -----\n","LEARNING RATE:  0.00038594475336178527\n","loss: 0.6188 (epoch: 16, step: 0) // Avg time/img: 0.1005 s\n","loss: 0.6646 (epoch: 16, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.6725 (epoch: 16, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6761 (epoch: 16, step: 150) // Avg time/img: 0.0889 s\n","loss: 0.6774 (epoch: 16, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 16 -----\n","VAL loss: 0.8178 (epoch: 16, step: 0) // Avg time/img: 0.0394 s\n","VAL loss: 0.8338 (epoch: 16, step: 50) // Avg time/img: 0.0330 s\n","VAL loss: 0.817 (epoch: 16, step: 100) // Avg time/img: 0.0340 s\n","VAL loss: 0.7756 (epoch: 16, step: 150) // Avg time/img: 0.0335 s\n","EPOCH IoU on VAL set:  \u001b[0m30.44\u001b[0m %\n","----- TRAINING - EPOCH 17 -----\n","LEARNING RATE:  0.00037821721103476613\n","loss: 0.6708 (epoch: 17, step: 0) // Avg time/img: 0.0855 s\n","loss: 0.6682 (epoch: 17, step: 50) // Avg time/img: 0.0883 s\n","loss: 0.6743 (epoch: 17, step: 100) // Avg time/img: 0.0887 s\n","loss: 0.6713 (epoch: 17, step: 150) // Avg time/img: 0.0886 s\n","loss: 0.6715 (epoch: 17, step: 200) // Avg time/img: 0.0885 s\n","----- VALIDATING - EPOCH 17 -----\n","VAL loss: 0.8398 (epoch: 17, step: 0) // Avg time/img: 0.0304 s\n","VAL loss: 0.8434 (epoch: 17, step: 50) // Avg time/img: 0.0318 s\n","VAL loss: 0.8231 (epoch: 17, step: 100) // Avg time/img: 0.0324 s\n","VAL loss: 0.7808 (epoch: 17, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m30.26\u001b[0m %\n","----- TRAINING - EPOCH 18 -----\n","LEARNING RATE:  0.00037047208454744316\n","loss: 0.6656 (epoch: 18, step: 0) // Avg time/img: 0.1005 s\n","loss: 0.6731 (epoch: 18, step: 50) // Avg time/img: 0.0911 s\n","loss: 0.6774 (epoch: 18, step: 100) // Avg time/img: 0.0900 s\n","loss: 0.6775 (epoch: 18, step: 150) // Avg time/img: 0.0892 s\n","loss: 0.672 (epoch: 18, step: 200) // Avg time/img: 0.0890 s\n","----- VALIDATING - EPOCH 18 -----\n","VAL loss: 0.7054 (epoch: 18, step: 0) // Avg time/img: 0.0363 s\n","VAL loss: 0.7997 (epoch: 18, step: 50) // Avg time/img: 0.0324 s\n","VAL loss: 0.785 (epoch: 18, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.7488 (epoch: 18, step: 150) // Avg time/img: 0.0325 s\n","EPOCH IoU on VAL set:  \u001b[0m32.24\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 18)\n","----- TRAINING - EPOCH 19 -----\n","LEARNING RATE:  0.00036270892346860996\n","loss: 0.6575 (epoch: 19, step: 0) // Avg time/img: 0.0883 s\n","loss: 0.6616 (epoch: 19, step: 50) // Avg time/img: 0.0886 s\n","loss: 0.661 (epoch: 19, step: 100) // Avg time/img: 0.0890 s\n","loss: 0.6596 (epoch: 19, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.6633 (epoch: 19, step: 200) // Avg time/img: 0.0890 s\n","----- VALIDATING - EPOCH 19 -----\n","VAL loss: 0.7856 (epoch: 19, step: 0) // Avg time/img: 0.0385 s\n","VAL loss: 0.8043 (epoch: 19, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.7922 (epoch: 19, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.756 (epoch: 19, step: 150) // Avg time/img: 0.0325 s\n","EPOCH IoU on VAL set:  \u001b[0m32.61\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 19)\n","----- TRAINING - EPOCH 20 -----\n","LEARNING RATE:  0.0003549272548125162\n","loss: 0.6391 (epoch: 20, step: 0) // Avg time/img: 0.0907 s\n","loss: 0.6595 (epoch: 20, step: 50) // Avg time/img: 0.0899 s\n","loss: 0.6647 (epoch: 20, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6617 (epoch: 20, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.6624 (epoch: 20, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 20 -----\n","VAL loss: 0.6834 (epoch: 20, step: 0) // Avg time/img: 0.0388 s\n","VAL loss: 0.7722 (epoch: 20, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.7767 (epoch: 20, step: 100) // Avg time/img: 0.0327 s\n","VAL loss: 0.7524 (epoch: 20, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m33.79\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 20)\n","----- TRAINING - EPOCH 21 -----\n","LEARNING RATE:  0.00034712658133080355\n","loss: 0.7166 (epoch: 21, step: 0) // Avg time/img: 0.0889 s\n","loss: 0.6658 (epoch: 21, step: 50) // Avg time/img: 0.0888 s\n","loss: 0.6652 (epoch: 21, step: 100) // Avg time/img: 0.0889 s\n","loss: 0.6602 (epoch: 21, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.6608 (epoch: 21, step: 200) // Avg time/img: 0.0884 s\n","----- VALIDATING - EPOCH 21 -----\n","VAL loss: 0.6914 (epoch: 21, step: 0) // Avg time/img: 0.0322 s\n","VAL loss: 0.7931 (epoch: 21, step: 50) // Avg time/img: 0.0322 s\n","VAL loss: 0.7885 (epoch: 21, step: 100) // Avg time/img: 0.0333 s\n","VAL loss: 0.7557 (epoch: 21, step: 150) // Avg time/img: 0.0330 s\n","EPOCH IoU on VAL set:  \u001b[0m32.93\u001b[0m %\n","----- TRAINING - EPOCH 22 -----\n","LEARNING RATE:  0.0003393063796290625\n","loss: 0.6758 (epoch: 22, step: 0) // Avg time/img: 0.0830 s\n","loss: 0.6612 (epoch: 22, step: 50) // Avg time/img: 0.0894 s\n","loss: 0.6586 (epoch: 22, step: 100) // Avg time/img: 0.0890 s\n","loss: 0.6574 (epoch: 22, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.6579 (epoch: 22, step: 200) // Avg time/img: 0.0883 s\n","----- VALIDATING - EPOCH 22 -----\n","VAL loss: 0.7919 (epoch: 22, step: 0) // Avg time/img: 0.0310 s\n","VAL loss: 0.8653 (epoch: 22, step: 50) // Avg time/img: 0.0322 s\n","VAL loss: 0.8483 (epoch: 22, step: 100) // Avg time/img: 0.0318 s\n","VAL loss: 0.7994 (epoch: 22, step: 150) // Avg time/img: 0.0319 s\n","EPOCH IoU on VAL set:  \u001b[0m32.24\u001b[0m %\n","----- TRAINING - EPOCH 23 -----\n","LEARNING RATE:  0.0003314660980850309\n","loss: 0.6045 (epoch: 23, step: 0) // Avg time/img: 0.0909 s\n","loss: 0.6536 (epoch: 23, step: 50) // Avg time/img: 0.0903 s\n","loss: 0.6527 (epoch: 23, step: 100) // Avg time/img: 0.0897 s\n","loss: 0.6517 (epoch: 23, step: 150) // Avg time/img: 0.0892 s\n","loss: 0.654 (epoch: 23, step: 200) // Avg time/img: 0.0889 s\n","----- VALIDATING - EPOCH 23 -----\n","VAL loss: 0.74 (epoch: 23, step: 0) // Avg time/img: 0.0365 s\n","VAL loss: 0.7717 (epoch: 23, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.7653 (epoch: 23, step: 100) // Avg time/img: 0.0324 s\n","VAL loss: 0.7333 (epoch: 23, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m35.83\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 23)\n","----- TRAINING - EPOCH 24 -----\n","LEARNING RATE:  0.0003236051545417615\n","loss: 0.6406 (epoch: 24, step: 0) // Avg time/img: 0.0925 s\n","loss: 0.6498 (epoch: 24, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.6458 (epoch: 24, step: 100) // Avg time/img: 0.0892 s\n","loss: 0.6515 (epoch: 24, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.6541 (epoch: 24, step: 200) // Avg time/img: 0.0890 s\n","----- VALIDATING - EPOCH 24 -----\n","VAL loss: 0.7265 (epoch: 24, step: 0) // Avg time/img: 0.0416 s\n","VAL loss: 0.784 (epoch: 24, step: 50) // Avg time/img: 0.0330 s\n","VAL loss: 0.7698 (epoch: 24, step: 100) // Avg time/img: 0.0325 s\n","VAL loss: 0.7371 (epoch: 24, step: 150) // Avg time/img: 0.0325 s\n","EPOCH IoU on VAL set:  \u001b[0m35.90\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 24)\n","----- TRAINING - EPOCH 25 -----\n","LEARNING RATE:  0.00031572293374467766\n","loss: 0.6754 (epoch: 25, step: 0) // Avg time/img: 0.1094 s\n","loss: 0.6456 (epoch: 25, step: 50) // Avg time/img: 0.0898 s\n","loss: 0.6536 (epoch: 25, step: 100) // Avg time/img: 0.0892 s\n","loss: 0.6501 (epoch: 25, step: 150) // Avg time/img: 0.0887 s\n","loss: 0.6472 (epoch: 25, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 25 -----\n","VAL loss: 0.7029 (epoch: 25, step: 0) // Avg time/img: 0.0382 s\n","VAL loss: 0.8037 (epoch: 25, step: 50) // Avg time/img: 0.0327 s\n","VAL loss: 0.7957 (epoch: 25, step: 100) // Avg time/img: 0.0329 s\n","VAL loss: 0.7592 (epoch: 25, step: 150) // Avg time/img: 0.0328 s\n","EPOCH IoU on VAL set:  \u001b[0m33.22\u001b[0m %\n","----- TRAINING - EPOCH 26 -----\n","LEARNING RATE:  0.00030781878448615926\n","loss: 0.6712 (epoch: 26, step: 0) // Avg time/img: 0.0873 s\n","loss: 0.6393 (epoch: 26, step: 50) // Avg time/img: 0.0892 s\n","loss: 0.6377 (epoch: 26, step: 100) // Avg time/img: 0.0893 s\n","loss: 0.6429 (epoch: 26, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.6424 (epoch: 26, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 26 -----\n","VAL loss: 0.7815 (epoch: 26, step: 0) // Avg time/img: 0.0357 s\n","VAL loss: 0.8232 (epoch: 26, step: 50) // Avg time/img: 0.0337 s\n","VAL loss: 0.7974 (epoch: 26, step: 100) // Avg time/img: 0.0340 s\n","VAL loss: 0.755 (epoch: 26, step: 150) // Avg time/img: 0.0336 s\n","EPOCH IoU on VAL set:  \u001b[0m33.57\u001b[0m %\n","----- TRAINING - EPOCH 27 -----\n","LEARNING RATE:  0.0002998920164149494\n","loss: 0.6186 (epoch: 27, step: 0) // Avg time/img: 0.1174 s\n","loss: 0.6415 (epoch: 27, step: 50) // Avg time/img: 0.0888 s\n","loss: 0.6418 (epoch: 27, step: 100) // Avg time/img: 0.0893 s\n","loss: 0.6424 (epoch: 27, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.6434 (epoch: 27, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 27 -----\n","VAL loss: 0.7293 (epoch: 27, step: 0) // Avg time/img: 0.0279 s\n","VAL loss: 0.7809 (epoch: 27, step: 50) // Avg time/img: 0.0320 s\n","VAL loss: 0.7774 (epoch: 27, step: 100) // Avg time/img: 0.0319 s\n","VAL loss: 0.7425 (epoch: 27, step: 150) // Avg time/img: 0.0320 s\n","EPOCH IoU on VAL set:  \u001b[0m35.35\u001b[0m %\n","----- TRAINING - EPOCH 28 -----\n","LEARNING RATE:  0.00029194189645999016\n","loss: 0.624 (epoch: 28, step: 0) // Avg time/img: 0.1230 s\n","loss: 0.6351 (epoch: 28, step: 50) // Avg time/img: 0.0900 s\n","loss: 0.6351 (epoch: 28, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6355 (epoch: 28, step: 150) // Avg time/img: 0.0889 s\n","loss: 0.6408 (epoch: 28, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 28 -----\n","VAL loss: 0.8068 (epoch: 28, step: 0) // Avg time/img: 0.0338 s\n","VAL loss: 0.8795 (epoch: 28, step: 50) // Avg time/img: 0.0325 s\n","VAL loss: 0.8624 (epoch: 28, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.8061 (epoch: 28, step: 150) // Avg time/img: 0.0320 s\n","EPOCH IoU on VAL set:  \u001b[0m32.73\u001b[0m %\n","----- TRAINING - EPOCH 29 -----\n","LEARNING RATE:  0.00028396764480896164\n","loss: 0.6507 (epoch: 29, step: 0) // Avg time/img: 0.0890 s\n","loss: 0.6273 (epoch: 29, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.6323 (epoch: 29, step: 100) // Avg time/img: 0.0899 s\n","loss: 0.6363 (epoch: 29, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.635 (epoch: 29, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 29 -----\n","VAL loss: 0.6818 (epoch: 29, step: 0) // Avg time/img: 0.0346 s\n","VAL loss: 0.823 (epoch: 29, step: 50) // Avg time/img: 0.0334 s\n","VAL loss: 0.8208 (epoch: 29, step: 100) // Avg time/img: 0.0331 s\n","VAL loss: 0.778 (epoch: 29, step: 150) // Avg time/img: 0.0329 s\n","EPOCH IoU on VAL set:  \u001b[0m33.60\u001b[0m %\n","----- TRAINING - EPOCH 30 -----\n","LEARNING RATE:  0.0002759684303703797\n","loss: 0.6836 (epoch: 30, step: 0) // Avg time/img: 0.0938 s\n","loss: 0.6412 (epoch: 30, step: 50) // Avg time/img: 0.0891 s\n","loss: 0.6377 (epoch: 30, step: 100) // Avg time/img: 0.0890 s\n","loss: 0.6358 (epoch: 30, step: 150) // Avg time/img: 0.0889 s\n","loss: 0.635 (epoch: 30, step: 200) // Avg time/img: 0.0893 s\n","----- VALIDATING - EPOCH 30 -----\n","VAL loss: 0.7287 (epoch: 30, step: 0) // Avg time/img: 0.0367 s\n","VAL loss: 0.7894 (epoch: 30, step: 50) // Avg time/img: 0.0327 s\n","VAL loss: 0.778 (epoch: 30, step: 100) // Avg time/img: 0.0327 s\n","VAL loss: 0.7435 (epoch: 30, step: 150) // Avg time/img: 0.0324 s\n","EPOCH IoU on VAL set:  \u001b[0m34.93\u001b[0m %\n","----- TRAINING - EPOCH 31 -----\n","LEARNING RATE:  0.0002679433656340733\n","loss: 0.6115 (epoch: 31, step: 0) // Avg time/img: 0.0826 s\n","loss: 0.6245 (epoch: 31, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.6259 (epoch: 31, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6266 (epoch: 31, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.6314 (epoch: 31, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 31 -----\n","VAL loss: 0.7176 (epoch: 31, step: 0) // Avg time/img: 0.0321 s\n","VAL loss: 0.785 (epoch: 31, step: 50) // Avg time/img: 0.0335 s\n","VAL loss: 0.7829 (epoch: 31, step: 100) // Avg time/img: 0.0336 s\n","VAL loss: 0.7482 (epoch: 31, step: 150) // Avg time/img: 0.0332 s\n","EPOCH IoU on VAL set:  \u001b[0m36.83\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 31)\n","----- TRAINING - EPOCH 32 -----\n","LEARNING RATE:  0.0002598915008274931\n","loss: 0.66 (epoch: 32, step: 0) // Avg time/img: 0.1134 s\n","loss: 0.6206 (epoch: 32, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.628 (epoch: 32, step: 100) // Avg time/img: 0.0892 s\n","loss: 0.6306 (epoch: 32, step: 150) // Avg time/img: 0.0887 s\n","loss: 0.6274 (epoch: 32, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 32 -----\n","VAL loss: 0.6757 (epoch: 32, step: 0) // Avg time/img: 0.0377 s\n","VAL loss: 0.7697 (epoch: 32, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.7606 (epoch: 32, step: 100) // Avg time/img: 0.0328 s\n","VAL loss: 0.7264 (epoch: 32, step: 150) // Avg time/img: 0.0329 s\n","EPOCH IoU on VAL set:  \u001b[0m37.08\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 32)\n","----- TRAINING - EPOCH 33 -----\n","LEARNING RATE:  0.00025181181724366923\n","loss: 0.6309 (epoch: 33, step: 0) // Avg time/img: 0.0878 s\n","loss: 0.6155 (epoch: 33, step: 50) // Avg time/img: 0.0886 s\n","loss: 0.6223 (epoch: 33, step: 100) // Avg time/img: 0.0888 s\n","loss: 0.6284 (epoch: 33, step: 150) // Avg time/img: 0.0888 s\n","loss: 0.6263 (epoch: 33, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 33 -----\n","VAL loss: 0.6543 (epoch: 33, step: 0) // Avg time/img: 0.0337 s\n","VAL loss: 0.7724 (epoch: 33, step: 50) // Avg time/img: 0.0330 s\n","VAL loss: 0.7658 (epoch: 33, step: 100) // Avg time/img: 0.0329 s\n","VAL loss: 0.7307 (epoch: 33, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m37.76\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 33)\n","----- TRAINING - EPOCH 34 -----\n","LEARNING RATE:  0.00024370321958949772\n","loss: 0.611 (epoch: 34, step: 0) // Avg time/img: 0.0947 s\n","loss: 0.6301 (epoch: 34, step: 50) // Avg time/img: 0.0894 s\n","loss: 0.6241 (epoch: 34, step: 100) // Avg time/img: 0.0906 s\n","loss: 0.6257 (epoch: 34, step: 150) // Avg time/img: 0.0896 s\n","loss: 0.6261 (epoch: 34, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 34 -----\n","VAL loss: 0.6864 (epoch: 34, step: 0) // Avg time/img: 0.0347 s\n","VAL loss: 0.7707 (epoch: 34, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.766 (epoch: 34, step: 100) // Avg time/img: 0.0327 s\n","VAL loss: 0.7317 (epoch: 34, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m38.13\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 34)\n","----- TRAINING - EPOCH 35 -----\n","LEARNING RATE:  0.00023556452716873652\n","loss: 0.59 (epoch: 35, step: 0) // Avg time/img: 0.0918 s\n","loss: 0.6196 (epoch: 35, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.6211 (epoch: 35, step: 100) // Avg time/img: 0.0889 s\n","loss: 0.6216 (epoch: 35, step: 150) // Avg time/img: 0.0888 s\n","loss: 0.6239 (epoch: 35, step: 200) // Avg time/img: 0.0889 s\n","----- VALIDATING - EPOCH 35 -----\n","VAL loss: 0.7319 (epoch: 35, step: 0) // Avg time/img: 0.0335 s\n","VAL loss: 0.7948 (epoch: 35, step: 50) // Avg time/img: 0.0331 s\n","VAL loss: 0.795 (epoch: 35, step: 100) // Avg time/img: 0.0325 s\n","VAL loss: 0.756 (epoch: 35, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m35.90\u001b[0m %\n","----- TRAINING - EPOCH 36 -----\n","LEARNING RATE:  0.00022739446367039517\n","loss: 0.6537 (epoch: 36, step: 0) // Avg time/img: 0.0877 s\n","loss: 0.6287 (epoch: 36, step: 50) // Avg time/img: 0.0890 s\n","loss: 0.6251 (epoch: 36, step: 100) // Avg time/img: 0.0889 s\n","loss: 0.6247 (epoch: 36, step: 150) // Avg time/img: 0.0887 s\n","loss: 0.6219 (epoch: 36, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 36 -----\n","VAL loss: 0.6969 (epoch: 36, step: 0) // Avg time/img: 0.0313 s\n","VAL loss: 0.7624 (epoch: 36, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.759 (epoch: 36, step: 100) // Avg time/img: 0.0333 s\n","VAL loss: 0.7278 (epoch: 36, step: 150) // Avg time/img: 0.0330 s\n","EPOCH IoU on VAL set:  \u001b[0m38.59\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 36)\n","----- TRAINING - EPOCH 37 -----\n","LEARNING RATE:  0.00021919164527704348\n","loss: 0.6107 (epoch: 37, step: 0) // Avg time/img: 0.0894 s\n","loss: 0.6165 (epoch: 37, step: 50) // Avg time/img: 0.0891 s\n","loss: 0.6167 (epoch: 37, step: 100) // Avg time/img: 0.0891 s\n","loss: 0.6173 (epoch: 37, step: 150) // Avg time/img: 0.0887 s\n","loss: 0.6187 (epoch: 37, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 37 -----\n","VAL loss: 0.6774 (epoch: 37, step: 0) // Avg time/img: 0.0397 s\n","VAL loss: 0.7566 (epoch: 37, step: 50) // Avg time/img: 0.0325 s\n","VAL loss: 0.7493 (epoch: 37, step: 100) // Avg time/img: 0.0322 s\n","VAL loss: 0.7193 (epoch: 37, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m38.91\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 37)\n","----- TRAINING - EPOCH 38 -----\n","LEARNING RATE:  0.00021095456673472888\n","loss: 0.634 (epoch: 38, step: 0) // Avg time/img: 0.0914 s\n","loss: 0.6161 (epoch: 38, step: 50) // Avg time/img: 0.0909 s\n","loss: 0.6179 (epoch: 38, step: 100) // Avg time/img: 0.0897 s\n","loss: 0.6225 (epoch: 38, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.621 (epoch: 38, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 38 -----\n","VAL loss: 0.6679 (epoch: 38, step: 0) // Avg time/img: 0.0323 s\n","VAL loss: 0.7519 (epoch: 38, step: 50) // Avg time/img: 0.0327 s\n","VAL loss: 0.7426 (epoch: 38, step: 100) // Avg time/img: 0.0327 s\n","VAL loss: 0.7113 (epoch: 38, step: 150) // Avg time/img: 0.0328 s\n","EPOCH IoU on VAL set:  \u001b[0m39.62\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 38)\n","----- TRAINING - EPOCH 39 -----\n","LEARNING RATE:  0.0002026815849307756\n","loss: 0.5979 (epoch: 39, step: 0) // Avg time/img: 0.0852 s\n","loss: 0.6102 (epoch: 39, step: 50) // Avg time/img: 0.0886 s\n","loss: 0.6138 (epoch: 39, step: 100) // Avg time/img: 0.0890 s\n","loss: 0.6161 (epoch: 39, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.6176 (epoch: 39, step: 200) // Avg time/img: 0.0889 s\n","----- VALIDATING - EPOCH 39 -----\n","VAL loss: 0.7211 (epoch: 39, step: 0) // Avg time/img: 0.0355 s\n","VAL loss: 0.766 (epoch: 39, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.7529 (epoch: 39, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.7179 (epoch: 39, step: 150) // Avg time/img: 0.0324 s\n","EPOCH IoU on VAL set:  \u001b[0m38.19\u001b[0m %\n","----- TRAINING - EPOCH 40 -----\n","LEARNING RATE:  0.00019437089939938174\n","loss: 0.5879 (epoch: 40, step: 0) // Avg time/img: 0.0873 s\n","loss: 0.6176 (epoch: 40, step: 50) // Avg time/img: 0.0899 s\n","loss: 0.6183 (epoch: 40, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.617 (epoch: 40, step: 150) // Avg time/img: 0.0889 s\n","loss: 0.6167 (epoch: 40, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 40 -----\n","VAL loss: 0.7517 (epoch: 40, step: 0) // Avg time/img: 0.0284 s\n","VAL loss: 0.8059 (epoch: 40, step: 50) // Avg time/img: 0.0325 s\n","VAL loss: 0.8071 (epoch: 40, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.7635 (epoch: 40, step: 150) // Avg time/img: 0.0321 s\n","EPOCH IoU on VAL set:  \u001b[0m37.15\u001b[0m %\n","----- TRAINING - EPOCH 41 -----\n","LEARNING RATE:  0.00018602052900565077\n","loss: 0.5956 (epoch: 41, step: 0) // Avg time/img: 0.0913 s\n","loss: 0.6188 (epoch: 41, step: 50) // Avg time/img: 0.0890 s\n","loss: 0.6164 (epoch: 41, step: 100) // Avg time/img: 0.0886 s\n","loss: 0.6181 (epoch: 41, step: 150) // Avg time/img: 0.0883 s\n","loss: 0.6146 (epoch: 41, step: 200) // Avg time/img: 0.0882 s\n","----- VALIDATING - EPOCH 41 -----\n","VAL loss: 0.7044 (epoch: 41, step: 0) // Avg time/img: 0.0331 s\n","VAL loss: 0.7654 (epoch: 41, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.7599 (epoch: 41, step: 100) // Avg time/img: 0.0326 s\n","VAL loss: 0.7278 (epoch: 41, step: 150) // Avg time/img: 0.0328 s\n","EPOCH IoU on VAL set:  \u001b[0m39.45\u001b[0m %\n","----- TRAINING - EPOCH 42 -----\n","LEARNING RATE:  0.00017762828382899407\n","loss: 0.5989 (epoch: 42, step: 0) // Avg time/img: 0.0959 s\n","loss: 0.6188 (epoch: 42, step: 50) // Avg time/img: 0.0892 s\n","loss: 0.6142 (epoch: 42, step: 100) // Avg time/img: 0.0888 s\n","loss: 0.6128 (epoch: 42, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.6133 (epoch: 42, step: 200) // Avg time/img: 0.0885 s\n","----- VALIDATING - EPOCH 42 -----\n","VAL loss: 0.6855 (epoch: 42, step: 0) // Avg time/img: 0.0314 s\n","VAL loss: 0.7688 (epoch: 42, step: 50) // Avg time/img: 0.0324 s\n","VAL loss: 0.7603 (epoch: 42, step: 100) // Avg time/img: 0.0324 s\n","VAL loss: 0.7269 (epoch: 42, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m39.16\u001b[0m %\n","----- TRAINING - EPOCH 43 -----\n","LEARNING RATE:  0.00016919173095082495\n","loss: 0.6579 (epoch: 43, step: 0) // Avg time/img: 0.0908 s\n","loss: 0.6179 (epoch: 43, step: 50) // Avg time/img: 0.0894 s\n","loss: 0.6136 (epoch: 43, step: 100) // Avg time/img: 0.0900 s\n","loss: 0.6141 (epoch: 43, step: 150) // Avg time/img: 0.0894 s\n","loss: 0.6118 (epoch: 43, step: 200) // Avg time/img: 0.0890 s\n","----- VALIDATING - EPOCH 43 -----\n","VAL loss: 0.6644 (epoch: 43, step: 0) // Avg time/img: 0.0327 s\n","VAL loss: 0.7495 (epoch: 43, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.7413 (epoch: 43, step: 100) // Avg time/img: 0.0328 s\n","VAL loss: 0.7087 (epoch: 43, step: 150) // Avg time/img: 0.0328 s\n","EPOCH IoU on VAL set:  \u001b[0m39.68\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 43)\n","----- TRAINING - EPOCH 44 -----\n","LEARNING RATE:  0.0001607081524100206\n","loss: 0.5968 (epoch: 44, step: 0) // Avg time/img: 0.0907 s\n","loss: 0.6046 (epoch: 44, step: 50) // Avg time/img: 0.0898 s\n","loss: 0.6037 (epoch: 44, step: 100) // Avg time/img: 0.0897 s\n","loss: 0.6041 (epoch: 44, step: 150) // Avg time/img: 0.0889 s\n","loss: 0.6058 (epoch: 44, step: 200) // Avg time/img: 0.0888 s\n","----- VALIDATING - EPOCH 44 -----\n","VAL loss: 0.7293 (epoch: 44, step: 0) // Avg time/img: 0.0305 s\n","VAL loss: 0.8313 (epoch: 44, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.8276 (epoch: 44, step: 100) // Avg time/img: 0.0324 s\n","VAL loss: 0.7776 (epoch: 44, step: 150) // Avg time/img: 0.0324 s\n","EPOCH IoU on VAL set:  \u001b[0m37.77\u001b[0m %\n","----- TRAINING - EPOCH 45 -----\n","LEARNING RATE:  0.00015217449296258857\n","loss: 0.5831 (epoch: 45, step: 0) // Avg time/img: 0.0945 s\n","loss: 0.6045 (epoch: 45, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.6053 (epoch: 45, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.6054 (epoch: 45, step: 150) // Avg time/img: 0.0888 s\n","loss: 0.6055 (epoch: 45, step: 200) // Avg time/img: 0.0885 s\n","----- VALIDATING - EPOCH 45 -----\n","VAL loss: 0.6429 (epoch: 45, step: 0) // Avg time/img: 0.0289 s\n","VAL loss: 0.7493 (epoch: 45, step: 50) // Avg time/img: 0.0333 s\n","VAL loss: 0.7514 (epoch: 45, step: 100) // Avg time/img: 0.0326 s\n","VAL loss: 0.7194 (epoch: 45, step: 150) // Avg time/img: 0.0325 s\n","EPOCH IoU on VAL set:  \u001b[0m39.87\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 45)\n","----- TRAINING - EPOCH 46 -----\n","LEARNING RATE:  0.00014358729437462936\n","loss: 0.5617 (epoch: 46, step: 0) // Avg time/img: 0.0868 s\n","loss: 0.6096 (epoch: 46, step: 50) // Avg time/img: 0.0888 s\n","loss: 0.6067 (epoch: 46, step: 100) // Avg time/img: 0.0886 s\n","loss: 0.6071 (epoch: 46, step: 150) // Avg time/img: 0.0884 s\n","loss: 0.6062 (epoch: 46, step: 200) // Avg time/img: 0.0882 s\n","----- VALIDATING - EPOCH 46 -----\n","VAL loss: 0.7084 (epoch: 46, step: 0) // Avg time/img: 0.0324 s\n","VAL loss: 0.7799 (epoch: 46, step: 50) // Avg time/img: 0.0322 s\n","VAL loss: 0.7785 (epoch: 46, step: 100) // Avg time/img: 0.0322 s\n","VAL loss: 0.7394 (epoch: 46, step: 150) // Avg time/img: 0.0321 s\n","EPOCH IoU on VAL set:  \u001b[0m39.13\u001b[0m %\n","----- TRAINING - EPOCH 47 -----\n","LEARNING RATE:  0.00013494261163740181\n","loss: 0.586 (epoch: 47, step: 0) // Avg time/img: 0.1272 s\n","loss: 0.6028 (epoch: 47, step: 50) // Avg time/img: 0.0906 s\n","loss: 0.6018 (epoch: 47, step: 100) // Avg time/img: 0.0896 s\n","loss: 0.603 (epoch: 47, step: 150) // Avg time/img: 0.0891 s\n","loss: 0.6046 (epoch: 47, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 47 -----\n","VAL loss: 0.6813 (epoch: 47, step: 0) // Avg time/img: 0.0355 s\n","VAL loss: 0.7637 (epoch: 47, step: 50) // Avg time/img: 0.0321 s\n","VAL loss: 0.7583 (epoch: 47, step: 100) // Avg time/img: 0.0319 s\n","VAL loss: 0.7243 (epoch: 47, step: 150) // Avg time/img: 0.0321 s\n","EPOCH IoU on VAL set:  \u001b[0m39.39\u001b[0m %\n","----- TRAINING - EPOCH 48 -----\n","LEARNING RATE:  0.00012623590446718072\n","loss: 0.6167 (epoch: 48, step: 0) // Avg time/img: 0.1046 s\n","loss: 0.5987 (epoch: 48, step: 50) // Avg time/img: 0.0897 s\n","loss: 0.5994 (epoch: 48, step: 100) // Avg time/img: 0.0894 s\n","loss: 0.5995 (epoch: 48, step: 150) // Avg time/img: 0.0895 s\n","loss: 0.5998 (epoch: 48, step: 200) // Avg time/img: 0.0892 s\n","----- VALIDATING - EPOCH 48 -----\n","VAL loss: 0.6654 (epoch: 48, step: 0) // Avg time/img: 0.0383 s\n","VAL loss: 0.7579 (epoch: 48, step: 50) // Avg time/img: 0.0329 s\n","VAL loss: 0.7524 (epoch: 48, step: 100) // Avg time/img: 0.0328 s\n","VAL loss: 0.7212 (epoch: 48, step: 150) // Avg time/img: 0.0328 s\n","EPOCH IoU on VAL set:  \u001b[0m40.15\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 48)\n","----- TRAINING - EPOCH 49 -----\n","LEARNING RATE:  0.00011746189430880188\n","loss: 0.5639 (epoch: 49, step: 0) // Avg time/img: 0.0879 s\n","loss: 0.5974 (epoch: 49, step: 50) // Avg time/img: 0.0896 s\n","loss: 0.5995 (epoch: 49, step: 100) // Avg time/img: 0.0893 s\n","loss: 0.601 (epoch: 49, step: 150) // Avg time/img: 0.0888 s\n","loss: 0.6002 (epoch: 49, step: 200) // Avg time/img: 0.0885 s\n","----- VALIDATING - EPOCH 49 -----\n","VAL loss: 0.6853 (epoch: 49, step: 0) // Avg time/img: 0.0265 s\n","VAL loss: 0.8074 (epoch: 49, step: 50) // Avg time/img: 0.0330 s\n","VAL loss: 0.8085 (epoch: 49, step: 100) // Avg time/img: 0.0325 s\n","VAL loss: 0.7639 (epoch: 49, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m37.84\u001b[0m %\n","----- TRAINING - EPOCH 50 -----\n","LEARNING RATE:  0.00010861437203680056\n","loss: 0.613 (epoch: 50, step: 0) // Avg time/img: 0.0945 s\n","loss: 0.5958 (epoch: 50, step: 50) // Avg time/img: 0.0893 s\n","loss: 0.5952 (epoch: 50, step: 100) // Avg time/img: 0.0891 s\n","loss: 0.5961 (epoch: 50, step: 150) // Avg time/img: 0.0887 s\n","loss: 0.5974 (epoch: 50, step: 200) // Avg time/img: 0.0884 s\n","----- VALIDATING - EPOCH 50 -----\n","VAL loss: 0.6731 (epoch: 50, step: 0) // Avg time/img: 0.0340 s\n","VAL loss: 0.7547 (epoch: 50, step: 50) // Avg time/img: 0.0323 s\n","VAL loss: 0.7534 (epoch: 50, step: 100) // Avg time/img: 0.0322 s\n","VAL loss: 0.7203 (epoch: 50, step: 150) // Avg time/img: 0.0327 s\n","EPOCH IoU on VAL set:  \u001b[0m40.12\u001b[0m %\n","----- TRAINING - EPOCH 51 -----\n","LEARNING RATE:  9.96859332376096e-05\n","loss: 0.6059 (epoch: 51, step: 0) // Avg time/img: 0.0856 s\n","loss: 0.5972 (epoch: 51, step: 50) // Avg time/img: 0.0889 s\n","loss: 0.5975 (epoch: 51, step: 100) // Avg time/img: 0.0887 s\n","loss: 0.596 (epoch: 51, step: 150) // Avg time/img: 0.0885 s\n","loss: 0.5969 (epoch: 51, step: 200) // Avg time/img: 0.0883 s\n","----- VALIDATING - EPOCH 51 -----\n","VAL loss: 0.6766 (epoch: 51, step: 0) // Avg time/img: 0.0342 s\n","VAL loss: 0.7609 (epoch: 51, step: 50) // Avg time/img: 0.0325 s\n","VAL loss: 0.7515 (epoch: 51, step: 100) // Avg time/img: 0.0321 s\n","VAL loss: 0.7173 (epoch: 51, step: 150) // Avg time/img: 0.0323 s\n","EPOCH IoU on VAL set:  \u001b[0m40.02\u001b[0m %\n","----- TRAINING - EPOCH 52 -----\n","LEARNING RATE:  9.066760365683728e-05\n","loss: 0.5784 (epoch: 52, step: 0) // Avg time/img: 0.0935 s\n","loss: 0.5928 (epoch: 52, step: 50) // Avg time/img: 0.0899 s\n","loss: 0.5934 (epoch: 52, step: 100) // Avg time/img: 0.0898 s\n","loss: 0.5942 (epoch: 52, step: 150) // Avg time/img: 0.0890 s\n","loss: 0.5953 (epoch: 52, step: 200) // Avg time/img: 0.0889 s\n","----- VALIDATING - EPOCH 52 -----\n","VAL loss: 0.6788 (epoch: 52, step: 0) // Avg time/img: 0.0344 s\n","VAL loss: 0.7806 (epoch: 52, step: 50) // Avg time/img: 0.0326 s\n","VAL loss: 0.775 (epoch: 52, step: 100) // Avg time/img: 0.0323 s\n","VAL loss: 0.7359 (epoch: 52, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m39.53\u001b[0m %\n","----- TRAINING - EPOCH 53 -----\n","LEARNING RATE:  8.154829161610912e-05\n","loss: 0.5908 (epoch: 53, step: 0) // Avg time/img: 0.0883 s\n","loss: 0.5945 (epoch: 53, step: 50) // Avg time/img: 0.0887 s\n","loss: 0.5927 (epoch: 53, step: 100) // Avg time/img: 0.0885 s\n","loss: 0.5931 (epoch: 53, step: 150) // Avg time/img: 0.0881 s\n","loss: 0.5935 (epoch: 53, step: 200) // Avg time/img: 0.0887 s\n","----- VALIDATING - EPOCH 53 -----\n","VAL loss: 0.6895 (epoch: 53, step: 0) // Avg time/img: 0.0305 s\n","VAL loss: 0.7595 (epoch: 53, step: 50) // Avg time/img: 0.0321 s\n","VAL loss: 0.7533 (epoch: 53, step: 100) // Avg time/img: 0.0322 s\n","VAL loss: 0.7188 (epoch: 53, step: 150) // Avg time/img: 0.0320 s\n","EPOCH IoU on VAL set:  \u001b[0m40.44\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 53)\n","----- TRAINING - EPOCH 54 -----\n","LEARNING RATE:  7.231395505915424e-05\n","loss: 0.6349 (epoch: 54, step: 0) // Avg time/img: 0.0881 s\n","loss: 0.594 (epoch: 54, step: 50) // Avg time/img: 0.0889 s\n","loss: 0.5917 (epoch: 54, step: 100) // Avg time/img: 0.0888 s\n","loss: 0.5909 (epoch: 54, step: 150) // Avg time/img: 0.0884 s\n","loss: 0.592 (epoch: 54, step: 200) // Avg time/img: 0.0884 s\n","----- VALIDATING - EPOCH 54 -----\n","VAL loss: 0.6512 (epoch: 54, step: 0) // Avg time/img: 0.0318 s\n","VAL loss: 0.7558 (epoch: 54, step: 50) // Avg time/img: 0.0333 s\n","VAL loss: 0.7484 (epoch: 54, step: 100) // Avg time/img: 0.0337 s\n","VAL loss: 0.7156 (epoch: 54, step: 150) // Avg time/img: 0.0332 s\n","EPOCH IoU on VAL set:  \u001b[0m40.61\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 54)\n","----- TRAINING - EPOCH 55 -----\n","LEARNING RATE:  6.294627058970836e-05\n","loss: 0.5934 (epoch: 55, step: 0) // Avg time/img: 0.0959 s\n","loss: 0.5934 (epoch: 55, step: 50) // Avg time/img: 0.0888 s\n","loss: 0.5926 (epoch: 55, step: 100) // Avg time/img: 0.0886 s\n","loss: 0.5915 (epoch: 55, step: 150) // Avg time/img: 0.0884 s\n","loss: 0.5899 (epoch: 55, step: 200) // Avg time/img: 0.0882 s\n","----- VALIDATING - EPOCH 55 -----\n","VAL loss: 0.6667 (epoch: 55, step: 0) // Avg time/img: 0.0386 s\n","VAL loss: 0.7416 (epoch: 55, step: 50) // Avg time/img: 0.0329 s\n","VAL loss: 0.729 (epoch: 55, step: 100) // Avg time/img: 0.0326 s\n","VAL loss: 0.6985 (epoch: 55, step: 150) // Avg time/img: 0.0326 s\n","EPOCH IoU on VAL set:  \u001b[0m41.44\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 55)\n","----- TRAINING - EPOCH 56 -----\n","LEARNING RATE:  5.3420368916117334e-05\n","loss: 0.5995 (epoch: 56, step: 0) // Avg time/img: 0.0829 s\n","loss: 0.5922 (epoch: 56, step: 50) // Avg time/img: 0.0903 s\n","loss: 0.5887 (epoch: 56, step: 100) // Avg time/img: 0.0896 s\n","loss: 0.5913 (epoch: 56, step: 150) // Avg time/img: 0.0888 s\n","loss: 0.5908 (epoch: 56, step: 200) // Avg time/img: 0.0886 s\n","----- VALIDATING - EPOCH 56 -----\n","VAL loss: 0.6768 (epoch: 56, step: 0) // Avg time/img: 0.0315 s\n","VAL loss: 0.7675 (epoch: 56, step: 50) // Avg time/img: 0.0338 s\n","VAL loss: 0.7584 (epoch: 56, step: 100) // Avg time/img: 0.0334 s\n","VAL loss: 0.7206 (epoch: 56, step: 150) // Avg time/img: 0.0331 s\n","EPOCH IoU on VAL set:  \u001b[0m40.86\u001b[0m %\n","----- TRAINING - EPOCH 57 -----\n","LEARNING RATE:  4.370064743465832e-05\n","loss: 0.5626 (epoch: 57, step: 0) // Avg time/img: 0.0922 s\n","loss: 0.5828 (epoch: 57, step: 50) // Avg time/img: 0.0896 s\n","loss: 0.5846 (epoch: 57, step: 100) // Avg time/img: 0.0896 s\n","loss: 0.5843 (epoch: 57, step: 150) // Avg time/img: 0.0898 s\n","loss: 0.5852 (epoch: 57, step: 200) // Avg time/img: 0.0894 s\n","----- VALIDATING - EPOCH 57 -----\n","VAL loss: 0.6744 (epoch: 57, step: 0) // Avg time/img: 0.0345 s\n","VAL loss: 0.7615 (epoch: 57, step: 50) // Avg time/img: 0.0328 s\n","VAL loss: 0.7517 (epoch: 57, step: 100) // Avg time/img: 0.0330 s\n","VAL loss: 0.7155 (epoch: 57, step: 150) // Avg time/img: 0.0329 s\n","EPOCH IoU on VAL set:  \u001b[0m40.42\u001b[0m %\n","----- TRAINING - EPOCH 58 -----\n","LEARNING RATE:  3.373207119183911e-05\n","loss: 0.5785 (epoch: 58, step: 0) // Avg time/img: 0.0893 s\n","loss: 0.5817 (epoch: 58, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.5861 (epoch: 58, step: 100) // Avg time/img: 0.0896 s\n","loss: 0.5851 (epoch: 58, step: 150) // Avg time/img: 0.0893 s\n","loss: 0.5856 (epoch: 58, step: 200) // Avg time/img: 0.0891 s\n","----- VALIDATING - EPOCH 58 -----\n","VAL loss: 0.6733 (epoch: 58, step: 0) // Avg time/img: 0.0367 s\n","VAL loss: 0.7401 (epoch: 58, step: 50) // Avg time/img: 0.0350 s\n","VAL loss: 0.7316 (epoch: 58, step: 100) // Avg time/img: 0.0341 s\n","VAL loss: 0.7014 (epoch: 58, step: 150) // Avg time/img: 0.0337 s\n","EPOCH IoU on VAL set:  \u001b[0m41.74\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 58)\n","----- TRAINING - EPOCH 59 -----\n","LEARNING RATE:  2.3418597108060762e-05\n","loss: 0.5625 (epoch: 59, step: 0) // Avg time/img: 0.1112 s\n","loss: 0.5827 (epoch: 59, step: 50) // Avg time/img: 0.0903 s\n","loss: 0.5852 (epoch: 59, step: 100) // Avg time/img: 0.0897 s\n","loss: 0.5859 (epoch: 59, step: 150) // Avg time/img: 0.0895 s\n","loss: 0.5868 (epoch: 59, step: 200) // Avg time/img: 0.0894 s\n","----- VALIDATING - EPOCH 59 -----\n","VAL loss: 0.6649 (epoch: 59, step: 0) // Avg time/img: 0.0367 s\n","VAL loss: 0.7511 (epoch: 59, step: 50) // Avg time/img: 0.0329 s\n","VAL loss: 0.7417 (epoch: 59, step: 100) // Avg time/img: 0.0325 s\n","VAL loss: 0.7083 (epoch: 59, step: 150) // Avg time/img: 0.0334 s\n","EPOCH IoU on VAL set:  \u001b[0m41.31\u001b[0m %\n","----- TRAINING - EPOCH 60 -----\n","LEARNING RATE:  1.254971545512439e-05\n","loss: 0.5576 (epoch: 60, step: 0) // Avg time/img: 0.0891 s\n","loss: 0.5844 (epoch: 60, step: 50) // Avg time/img: 0.0895 s\n","loss: 0.5856 (epoch: 60, step: 100) // Avg time/img: 0.0898 s\n","loss: 0.586 (epoch: 60, step: 150) // Avg time/img: 0.0895 s\n","loss: 0.5865 (epoch: 60, step: 200) // Avg time/img: 0.0892 s\n","----- VALIDATING - EPOCH 60 -----\n","VAL loss: 0.6532 (epoch: 60, step: 0) // Avg time/img: 0.0367 s\n","VAL loss: 0.7424 (epoch: 60, step: 50) // Avg time/img: 0.0340 s\n","VAL loss: 0.7327 (epoch: 60, step: 100) // Avg time/img: 0.0334 s\n","VAL loss: 0.7015 (epoch: 60, step: 150) // Avg time/img: 0.0331 s\n","EPOCH IoU on VAL set:  \u001b[0m41.92\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_encoder_best.pth (epoch: 60)\n","========== DECODER TRAINING ===========\n","/content/gdrive/MyDrive/Colab Notebooks/cityscapes/leftImg8bit/train\n","/content/gdrive/MyDrive/Colab Notebooks/cityscapes/leftImg8bit/val\n","<class '__main__.MainLoss'>\n","----- TRAINING - EPOCH 1 -----\n","LEARNING RATE:  0.0005\n","loss: 15.36 (epoch: 1, step: 0) // Avg time/img: 0.1682 s\n","loss: 15.49 (epoch: 1, step: 50) // Avg time/img: 0.1367 s\n","loss: 14.49 (epoch: 1, step: 100) // Avg time/img: 0.1367 s\n","loss: 13.34 (epoch: 1, step: 150) // Avg time/img: 0.1353 s\n","loss: 12.34 (epoch: 1, step: 200) // Avg time/img: 0.1348 s\n","----- VALIDATING - EPOCH 1 -----\n","VAL loss: 6.294 (epoch: 1, step: 0) // Avg time/img: 0.0573 s\n","VAL loss: 7.122 (epoch: 1, step: 50) // Avg time/img: 0.0491 s\n","VAL loss: 6.899 (epoch: 1, step: 100) // Avg time/img: 0.0484 s\n","VAL loss: 6.775 (epoch: 1, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m9.63\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 1)\n","----- TRAINING - EPOCH 2 -----\n","LEARNING RATE:  0.000492493711467861\n","loss: 6.961 (epoch: 2, step: 0) // Avg time/img: 0.1570 s\n","loss: 6.597 (epoch: 2, step: 50) // Avg time/img: 0.1363 s\n","loss: 6.104 (epoch: 2, step: 100) // Avg time/img: 0.1365 s\n","loss: 5.719 (epoch: 2, step: 150) // Avg time/img: 0.1355 s\n","loss: 5.415 (epoch: 2, step: 200) // Avg time/img: 0.1350 s\n","----- VALIDATING - EPOCH 2 -----\n","VAL loss: 3.614 (epoch: 2, step: 0) // Avg time/img: 0.0507 s\n","VAL loss: 4.231 (epoch: 2, step: 50) // Avg time/img: 0.0476 s\n","VAL loss: 4.131 (epoch: 2, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 3.973 (epoch: 2, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m15.93\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 2)\n","----- TRAINING - EPOCH 3 -----\n","LEARNING RATE:  0.0004849746889841331\n","loss: 3.225 (epoch: 3, step: 0) // Avg time/img: 0.1646 s\n","loss: 3.86 (epoch: 3, step: 50) // Avg time/img: 0.1363 s\n","loss: 3.598 (epoch: 3, step: 100) // Avg time/img: 0.1363 s\n","loss: 3.437 (epoch: 3, step: 150) // Avg time/img: 0.1352 s\n","loss: 3.31 (epoch: 3, step: 200) // Avg time/img: 0.1348 s\n","----- VALIDATING - EPOCH 3 -----\n","VAL loss: 3.134 (epoch: 3, step: 0) // Avg time/img: 0.0485 s\n","VAL loss: 3.649 (epoch: 3, step: 50) // Avg time/img: 0.0480 s\n","VAL loss: 3.603 (epoch: 3, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 3.371 (epoch: 3, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m18.84\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 3)\n","----- TRAINING - EPOCH 4 -----\n","LEARNING RATE:  0.00047744269081074987\n","loss: 2.919 (epoch: 4, step: 0) // Avg time/img: 0.1607 s\n","loss: 2.617 (epoch: 4, step: 50) // Avg time/img: 0.1355 s\n","loss: 2.571 (epoch: 4, step: 100) // Avg time/img: 0.1361 s\n","loss: 2.527 (epoch: 4, step: 150) // Avg time/img: 0.1353 s\n","loss: 2.492 (epoch: 4, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 4 -----\n","VAL loss: 1.889 (epoch: 4, step: 0) // Avg time/img: 0.0549 s\n","VAL loss: 2.667 (epoch: 4, step: 50) // Avg time/img: 0.0485 s\n","VAL loss: 2.598 (epoch: 4, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 2.408 (epoch: 4, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m24.27\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 4)\n","----- TRAINING - EPOCH 5 -----\n","LEARNING RATE:  0.00046989746629436113\n","loss: 2.338 (epoch: 5, step: 0) // Avg time/img: 0.1615 s\n","loss: 2.203 (epoch: 5, step: 50) // Avg time/img: 0.1361 s\n","loss: 2.126 (epoch: 5, step: 100) // Avg time/img: 0.1362 s\n","loss: 2.104 (epoch: 5, step: 150) // Avg time/img: 0.1351 s\n","loss: 2.077 (epoch: 5, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 5 -----\n","VAL loss: 1.912 (epoch: 5, step: 0) // Avg time/img: 0.0502 s\n","VAL loss: 2.441 (epoch: 5, step: 50) // Avg time/img: 0.0483 s\n","VAL loss: 2.381 (epoch: 5, step: 100) // Avg time/img: 0.0482 s\n","VAL loss: 2.187 (epoch: 5, step: 150) // Avg time/img: 0.0482 s\n","EPOCH IoU on VAL set:  \u001b[0m25.58\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 5)\n","----- TRAINING - EPOCH 6 -----\n","LEARNING RATE:  0.0004623387553722673\n","loss: 4.105 (epoch: 6, step: 0) // Avg time/img: 0.1540 s\n","loss: 1.819 (epoch: 6, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.807 (epoch: 6, step: 100) // Avg time/img: 0.1354 s\n","loss: 1.827 (epoch: 6, step: 150) // Avg time/img: 0.1351 s\n","loss: 1.835 (epoch: 6, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 6 -----\n","VAL loss: 1.781 (epoch: 6, step: 0) // Avg time/img: 0.0590 s\n","VAL loss: 2.464 (epoch: 6, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 2.401 (epoch: 6, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 2.18 (epoch: 6, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m26.57\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 6)\n","----- TRAINING - EPOCH 7 -----\n","LEARNING RATE:  0.00045476628804148113\n","loss: 2.051 (epoch: 7, step: 0) // Avg time/img: 0.1575 s\n","loss: 1.769 (epoch: 7, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.73 (epoch: 7, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.766 (epoch: 7, step: 150) // Avg time/img: 0.1349 s\n","loss: 1.777 (epoch: 7, step: 200) // Avg time/img: 0.1344 s\n","----- VALIDATING - EPOCH 7 -----\n","VAL loss: 1.695 (epoch: 7, step: 0) // Avg time/img: 0.0563 s\n","VAL loss: 2.414 (epoch: 7, step: 50) // Avg time/img: 0.0484 s\n","VAL loss: 2.302 (epoch: 7, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 2.083 (epoch: 7, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m28.39\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 7)\n","----- TRAINING - EPOCH 8 -----\n","LEARNING RATE:  0.00044717978378742816\n","loss: 1.195 (epoch: 8, step: 0) // Avg time/img: 0.1581 s\n","loss: 1.609 (epoch: 8, step: 50) // Avg time/img: 0.1357 s\n","loss: 1.643 (epoch: 8, step: 100) // Avg time/img: 0.1343 s\n","loss: 1.635 (epoch: 8, step: 150) // Avg time/img: 0.1350 s\n","loss: 1.632 (epoch: 8, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 8 -----\n","VAL loss: 1.39 (epoch: 8, step: 0) // Avg time/img: 0.0505 s\n","VAL loss: 2.071 (epoch: 8, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 2.092 (epoch: 8, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.929 (epoch: 8, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m30.18\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 8)\n","----- TRAINING - EPOCH 9 -----\n","LEARNING RATE:  0.00043957895096839955\n","loss: 2.017 (epoch: 9, step: 0) // Avg time/img: 0.1607 s\n","loss: 1.62 (epoch: 9, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.542 (epoch: 9, step: 100) // Avg time/img: 0.1343 s\n","loss: 1.525 (epoch: 9, step: 150) // Avg time/img: 0.1350 s\n","loss: 1.507 (epoch: 9, step: 200) // Avg time/img: 0.1345 s\n","----- VALIDATING - EPOCH 9 -----\n","VAL loss: 1.637 (epoch: 9, step: 0) // Avg time/img: 0.0460 s\n","VAL loss: 2.152 (epoch: 9, step: 50) // Avg time/img: 0.0480 s\n","VAL loss: 2.085 (epoch: 9, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.915 (epoch: 9, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m31.03\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 9)\n","----- TRAINING - EPOCH 10 -----\n","LEARNING RATE:  0.00043196348615140955\n","loss: 1.175 (epoch: 10, step: 0) // Avg time/img: 0.1530 s\n","loss: 1.502 (epoch: 10, step: 50) // Avg time/img: 0.1351 s\n","loss: 1.484 (epoch: 10, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.48 (epoch: 10, step: 150) // Avg time/img: 0.1347 s\n","loss: 1.491 (epoch: 10, step: 200) // Avg time/img: 0.1343 s\n","----- VALIDATING - EPOCH 10 -----\n","VAL loss: 1.556 (epoch: 10, step: 0) // Avg time/img: 0.0496 s\n","VAL loss: 2.03 (epoch: 10, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 2.027 (epoch: 10, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.834 (epoch: 10, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m32.82\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 10)\n","----- TRAINING - EPOCH 11 -----\n","LEARNING RATE:  0.00042433307339459345\n","loss: 1.739 (epoch: 11, step: 0) // Avg time/img: 0.1406 s\n","loss: 1.56 (epoch: 11, step: 50) // Avg time/img: 0.1361 s\n","loss: 1.513 (epoch: 11, step: 100) // Avg time/img: 0.1344 s\n","loss: 1.525 (epoch: 11, step: 150) // Avg time/img: 0.1342 s\n","loss: 1.466 (epoch: 11, step: 200) // Avg time/img: 0.1345 s\n","----- VALIDATING - EPOCH 11 -----\n","VAL loss: 1.861 (epoch: 11, step: 0) // Avg time/img: 0.0521 s\n","VAL loss: 2.135 (epoch: 11, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 2.145 (epoch: 11, step: 100) // Avg time/img: 0.0479 s\n","VAL loss: 1.923 (epoch: 11, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m33.56\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 11)\n","----- TRAINING - EPOCH 12 -----\n","LEARNING RATE:  0.0004166873834706844\n","loss: 1.26 (epoch: 12, step: 0) // Avg time/img: 0.1667 s\n","loss: 1.364 (epoch: 12, step: 50) // Avg time/img: 0.1352 s\n","loss: 1.307 (epoch: 12, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.282 (epoch: 12, step: 150) // Avg time/img: 0.1337 s\n","loss: 1.28 (epoch: 12, step: 200) // Avg time/img: 0.1345 s\n","----- VALIDATING - EPOCH 12 -----\n","VAL loss: 1.46 (epoch: 12, step: 0) // Avg time/img: 0.0491 s\n","VAL loss: 2.203 (epoch: 12, step: 50) // Avg time/img: 0.0477 s\n","VAL loss: 2.196 (epoch: 12, step: 100) // Avg time/img: 0.0476 s\n","VAL loss: 1.977 (epoch: 12, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m34.63\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 12)\n","----- TRAINING - EPOCH 13 -----\n","LEARNING RATE:  0.00040902607302542923\n","loss: 1.092 (epoch: 13, step: 0) // Avg time/img: 0.1610 s\n","loss: 1.154 (epoch: 13, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.218 (epoch: 13, step: 100) // Avg time/img: 0.1344 s\n","loss: 1.225 (epoch: 13, step: 150) // Avg time/img: 0.1339 s\n","loss: 1.226 (epoch: 13, step: 200) // Avg time/img: 0.1345 s\n","----- VALIDATING - EPOCH 13 -----\n","VAL loss: 2.287 (epoch: 13, step: 0) // Avg time/img: 0.0464 s\n","VAL loss: 2.212 (epoch: 13, step: 50) // Avg time/img: 0.0487 s\n","VAL loss: 2.259 (epoch: 13, step: 100) // Avg time/img: 0.0483 s\n","VAL loss: 2.024 (epoch: 13, step: 150) // Avg time/img: 0.0482 s\n","EPOCH IoU on VAL set:  \u001b[0m32.65\u001b[0m %\n","----- TRAINING - EPOCH 14 -----\n","LEARNING RATE:  0.0004013487836640184\n","loss: 1.276 (epoch: 14, step: 0) // Avg time/img: 0.1598 s\n","loss: 1.356 (epoch: 14, step: 50) // Avg time/img: 0.1355 s\n","loss: 1.34 (epoch: 14, step: 100) // Avg time/img: 0.1345 s\n","loss: 1.274 (epoch: 14, step: 150) // Avg time/img: 0.1338 s\n","loss: 1.266 (epoch: 14, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 14 -----\n","VAL loss: 1.309 (epoch: 14, step: 0) // Avg time/img: 0.0633 s\n","VAL loss: 1.95 (epoch: 14, step: 50) // Avg time/img: 0.0490 s\n","VAL loss: 1.937 (epoch: 14, step: 100) // Avg time/img: 0.0486 s\n","VAL loss: 1.723 (epoch: 14, step: 150) // Avg time/img: 0.0483 s\n","EPOCH IoU on VAL set:  \u001b[0m35.73\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 14)\n","----- TRAINING - EPOCH 15 -----\n","LEARNING RATE:  0.0003936551409577103\n","loss: 2.494 (epoch: 15, step: 0) // Avg time/img: 0.1561 s\n","loss: 1.242 (epoch: 15, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.172 (epoch: 15, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.186 (epoch: 15, step: 150) // Avg time/img: 0.1341 s\n","loss: 1.197 (epoch: 15, step: 200) // Avg time/img: 0.1348 s\n","----- VALIDATING - EPOCH 15 -----\n","VAL loss: 1.146 (epoch: 15, step: 0) // Avg time/img: 0.0530 s\n","VAL loss: 1.753 (epoch: 15, step: 50) // Avg time/img: 0.0479 s\n","VAL loss: 1.731 (epoch: 15, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.555 (epoch: 15, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m37.37\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 15)\n","----- TRAINING - EPOCH 16 -----\n","LEARNING RATE:  0.00038594475336178527\n","loss: 0.9435 (epoch: 16, step: 0) // Avg time/img: 0.1588 s\n","loss: 1.169 (epoch: 16, step: 50) // Avg time/img: 0.1368 s\n","loss: 1.141 (epoch: 16, step: 100) // Avg time/img: 0.1351 s\n","loss: 1.152 (epoch: 16, step: 150) // Avg time/img: 0.1345 s\n","loss: 1.17 (epoch: 16, step: 200) // Avg time/img: 0.1350 s\n","----- VALIDATING - EPOCH 16 -----\n","VAL loss: 2.255 (epoch: 16, step: 0) // Avg time/img: 0.0522 s\n","VAL loss: 2.222 (epoch: 16, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 2.224 (epoch: 16, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.967 (epoch: 16, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m36.22\u001b[0m %\n","----- TRAINING - EPOCH 17 -----\n","LEARNING RATE:  0.00037821721103476613\n","loss: 1.135 (epoch: 17, step: 0) // Avg time/img: 0.1709 s\n","loss: 1.219 (epoch: 17, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.154 (epoch: 17, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.131 (epoch: 17, step: 150) // Avg time/img: 0.1338 s\n","loss: 1.118 (epoch: 17, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 17 -----\n","VAL loss: 1.347 (epoch: 17, step: 0) // Avg time/img: 0.0539 s\n","VAL loss: 1.905 (epoch: 17, step: 50) // Avg time/img: 0.0478 s\n","VAL loss: 1.874 (epoch: 17, step: 100) // Avg time/img: 0.0479 s\n","VAL loss: 1.651 (epoch: 17, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m37.29\u001b[0m %\n","----- TRAINING - EPOCH 18 -----\n","LEARNING RATE:  0.00037047208454744316\n","loss: 1.16 (epoch: 18, step: 0) // Avg time/img: 0.1420 s\n","loss: 1.017 (epoch: 18, step: 50) // Avg time/img: 0.1357 s\n","loss: 1.034 (epoch: 18, step: 100) // Avg time/img: 0.1341 s\n","loss: 1.048 (epoch: 18, step: 150) // Avg time/img: 0.1338 s\n","loss: 1.066 (epoch: 18, step: 200) // Avg time/img: 0.1338 s\n","----- VALIDATING - EPOCH 18 -----\n","VAL loss: 1.291 (epoch: 18, step: 0) // Avg time/img: 0.0542 s\n","VAL loss: 1.743 (epoch: 18, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.73 (epoch: 18, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.541 (epoch: 18, step: 150) // Avg time/img: 0.0480 s\n","EPOCH IoU on VAL set:  \u001b[0m39.81\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 18)\n","----- TRAINING - EPOCH 19 -----\n","LEARNING RATE:  0.00036270892346860996\n","loss: 0.7523 (epoch: 19, step: 0) // Avg time/img: 0.1337 s\n","loss: 1.131 (epoch: 19, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.06 (epoch: 19, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.047 (epoch: 19, step: 150) // Avg time/img: 0.1338 s\n","loss: 1.045 (epoch: 19, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 19 -----\n","VAL loss: 1.471 (epoch: 19, step: 0) // Avg time/img: 0.0470 s\n","VAL loss: 1.858 (epoch: 19, step: 50) // Avg time/img: 0.0475 s\n","VAL loss: 1.898 (epoch: 19, step: 100) // Avg time/img: 0.0471 s\n","VAL loss: 1.726 (epoch: 19, step: 150) // Avg time/img: 0.0472 s\n","EPOCH IoU on VAL set:  \u001b[0m40.47\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 19)\n","----- TRAINING - EPOCH 20 -----\n","LEARNING RATE:  0.0003549272548125162\n","loss: 1.128 (epoch: 20, step: 0) // Avg time/img: 0.1461 s\n","loss: 1.033 (epoch: 20, step: 50) // Avg time/img: 0.1354 s\n","loss: 1.015 (epoch: 20, step: 100) // Avg time/img: 0.1342 s\n","loss: 1.035 (epoch: 20, step: 150) // Avg time/img: 0.1337 s\n","loss: 1.042 (epoch: 20, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 20 -----\n","VAL loss: 1.145 (epoch: 20, step: 0) // Avg time/img: 0.0673 s\n","VAL loss: 1.67 (epoch: 20, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.661 (epoch: 20, step: 100) // Avg time/img: 0.0477 s\n","VAL loss: 1.491 (epoch: 20, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m40.10\u001b[0m %\n","----- TRAINING - EPOCH 21 -----\n","LEARNING RATE:  0.00034712658133080355\n","loss: 0.9952 (epoch: 21, step: 0) // Avg time/img: 0.1355 s\n","loss: 0.9919 (epoch: 21, step: 50) // Avg time/img: 0.1356 s\n","loss: 0.9635 (epoch: 21, step: 100) // Avg time/img: 0.1344 s\n","loss: 0.9957 (epoch: 21, step: 150) // Avg time/img: 0.1344 s\n","loss: 1.019 (epoch: 21, step: 200) // Avg time/img: 0.1340 s\n","----- VALIDATING - EPOCH 21 -----\n","VAL loss: 1.383 (epoch: 21, step: 0) // Avg time/img: 0.0558 s\n","VAL loss: 1.876 (epoch: 21, step: 50) // Avg time/img: 0.0494 s\n","VAL loss: 1.913 (epoch: 21, step: 100) // Avg time/img: 0.0486 s\n","VAL loss: 1.709 (epoch: 21, step: 150) // Avg time/img: 0.0482 s\n","EPOCH IoU on VAL set:  \u001b[0m38.61\u001b[0m %\n","----- TRAINING - EPOCH 22 -----\n","LEARNING RATE:  0.0003393063796290625\n","loss: 0.7803 (epoch: 22, step: 0) // Avg time/img: 0.1395 s\n","loss: 0.9767 (epoch: 22, step: 50) // Avg time/img: 0.1352 s\n","loss: 0.9674 (epoch: 22, step: 100) // Avg time/img: 0.1341 s\n","loss: 0.9916 (epoch: 22, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.988 (epoch: 22, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 22 -----\n","VAL loss: 1.249 (epoch: 22, step: 0) // Avg time/img: 0.0567 s\n","VAL loss: 1.734 (epoch: 22, step: 50) // Avg time/img: 0.0497 s\n","VAL loss: 1.794 (epoch: 22, step: 100) // Avg time/img: 0.0488 s\n","VAL loss: 1.605 (epoch: 22, step: 150) // Avg time/img: 0.0483 s\n","EPOCH IoU on VAL set:  \u001b[0m39.47\u001b[0m %\n","----- TRAINING - EPOCH 23 -----\n","LEARNING RATE:  0.0003314660980850309\n","loss: 2.17 (epoch: 23, step: 0) // Avg time/img: 0.1423 s\n","loss: 0.9497 (epoch: 23, step: 50) // Avg time/img: 0.1355 s\n","loss: 0.9583 (epoch: 23, step: 100) // Avg time/img: 0.1342 s\n","loss: 0.98 (epoch: 23, step: 150) // Avg time/img: 0.1335 s\n","loss: 0.9697 (epoch: 23, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 23 -----\n","VAL loss: 1.432 (epoch: 23, step: 0) // Avg time/img: 0.0545 s\n","VAL loss: 1.966 (epoch: 23, step: 50) // Avg time/img: 0.0498 s\n","VAL loss: 2.082 (epoch: 23, step: 100) // Avg time/img: 0.0491 s\n","VAL loss: 1.86 (epoch: 23, step: 150) // Avg time/img: 0.0488 s\n","EPOCH IoU on VAL set:  \u001b[0m38.09\u001b[0m %\n","----- TRAINING - EPOCH 24 -----\n","LEARNING RATE:  0.0003236051545417615\n","loss: 1.009 (epoch: 24, step: 0) // Avg time/img: 0.1527 s\n","loss: 0.9291 (epoch: 24, step: 50) // Avg time/img: 0.1349 s\n","loss: 0.9622 (epoch: 24, step: 100) // Avg time/img: 0.1337 s\n","loss: 0.9427 (epoch: 24, step: 150) // Avg time/img: 0.1333 s\n","loss: 0.9591 (epoch: 24, step: 200) // Avg time/img: 0.1333 s\n","----- VALIDATING - EPOCH 24 -----\n","VAL loss: 1.632 (epoch: 24, step: 0) // Avg time/img: 0.0542 s\n","VAL loss: 1.874 (epoch: 24, step: 50) // Avg time/img: 0.0486 s\n","VAL loss: 1.902 (epoch: 24, step: 100) // Avg time/img: 0.0489 s\n","VAL loss: 1.672 (epoch: 24, step: 150) // Avg time/img: 0.0485 s\n","EPOCH IoU on VAL set:  \u001b[0m40.28\u001b[0m %\n","----- TRAINING - EPOCH 25 -----\n","LEARNING RATE:  0.00031572293374467766\n","loss: 0.7549 (epoch: 25, step: 0) // Avg time/img: 0.1388 s\n","loss: 0.8776 (epoch: 25, step: 50) // Avg time/img: 0.1349 s\n","loss: 0.9212 (epoch: 25, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.9282 (epoch: 25, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.921 (epoch: 25, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 25 -----\n","VAL loss: 1.053 (epoch: 25, step: 0) // Avg time/img: 0.0455 s\n","VAL loss: 1.626 (epoch: 25, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 1.615 (epoch: 25, step: 100) // Avg time/img: 0.0487 s\n","VAL loss: 1.433 (epoch: 25, step: 150) // Avg time/img: 0.0484 s\n","EPOCH IoU on VAL set:  \u001b[0m41.45\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 25)\n","----- TRAINING - EPOCH 26 -----\n","LEARNING RATE:  0.00030781878448615926\n","loss: 0.5784 (epoch: 26, step: 0) // Avg time/img: 0.1579 s\n","loss: 0.9328 (epoch: 26, step: 50) // Avg time/img: 0.1354 s\n","loss: 0.895 (epoch: 26, step: 100) // Avg time/img: 0.1342 s\n","loss: 0.8921 (epoch: 26, step: 150) // Avg time/img: 0.1338 s\n","loss: 0.8995 (epoch: 26, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 26 -----\n","VAL loss: 0.9851 (epoch: 26, step: 0) // Avg time/img: 0.0504 s\n","VAL loss: 1.613 (epoch: 26, step: 50) // Avg time/img: 0.0478 s\n","VAL loss: 1.604 (epoch: 26, step: 100) // Avg time/img: 0.0483 s\n","VAL loss: 1.427 (epoch: 26, step: 150) // Avg time/img: 0.0485 s\n","EPOCH IoU on VAL set:  \u001b[0m41.65\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 26)\n","----- TRAINING - EPOCH 27 -----\n","LEARNING RATE:  0.0002998920164149494\n","loss: 0.9363 (epoch: 27, step: 0) // Avg time/img: 0.1408 s\n","loss: 0.8785 (epoch: 27, step: 50) // Avg time/img: 0.1357 s\n","loss: 0.85 (epoch: 27, step: 100) // Avg time/img: 0.1343 s\n","loss: 0.8731 (epoch: 27, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.9046 (epoch: 27, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 27 -----\n","VAL loss: 1.512 (epoch: 27, step: 0) // Avg time/img: 0.0520 s\n","VAL loss: 1.762 (epoch: 27, step: 50) // Avg time/img: 0.0478 s\n","VAL loss: 1.767 (epoch: 27, step: 100) // Avg time/img: 0.0475 s\n","VAL loss: 1.57 (epoch: 27, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m39.49\u001b[0m %\n","----- TRAINING - EPOCH 28 -----\n","LEARNING RATE:  0.00029194189645999016\n","loss: 1.549 (epoch: 28, step: 0) // Avg time/img: 0.1470 s\n","loss: 1.037 (epoch: 28, step: 50) // Avg time/img: 0.1352 s\n","loss: 0.9644 (epoch: 28, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.9379 (epoch: 28, step: 150) // Avg time/img: 0.1336 s\n","loss: 0.9212 (epoch: 28, step: 200) // Avg time/img: 0.1334 s\n","----- VALIDATING - EPOCH 28 -----\n","VAL loss: 1.204 (epoch: 28, step: 0) // Avg time/img: 0.0476 s\n","VAL loss: 1.571 (epoch: 28, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 1.591 (epoch: 28, step: 100) // Avg time/img: 0.0479 s\n","VAL loss: 1.439 (epoch: 28, step: 150) // Avg time/img: 0.0484 s\n","EPOCH IoU on VAL set:  \u001b[0m42.09\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 28)\n","----- TRAINING - EPOCH 29 -----\n","LEARNING RATE:  0.00028396764480896164\n","loss: 0.6797 (epoch: 29, step: 0) // Avg time/img: 0.1585 s\n","loss: 0.8972 (epoch: 29, step: 50) // Avg time/img: 0.1354 s\n","loss: 0.857 (epoch: 29, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.8652 (epoch: 29, step: 150) // Avg time/img: 0.1338 s\n","loss: 0.8535 (epoch: 29, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 29 -----\n","VAL loss: 1.25 (epoch: 29, step: 0) // Avg time/img: 0.0519 s\n","VAL loss: 1.748 (epoch: 29, step: 50) // Avg time/img: 0.0483 s\n","VAL loss: 1.748 (epoch: 29, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.533 (epoch: 29, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m40.07\u001b[0m %\n","----- TRAINING - EPOCH 30 -----\n","LEARNING RATE:  0.0002759684303703797\n","loss: 0.7381 (epoch: 30, step: 0) // Avg time/img: 0.1744 s\n","loss: 0.8765 (epoch: 30, step: 50) // Avg time/img: 0.1377 s\n","loss: 0.8405 (epoch: 30, step: 100) // Avg time/img: 0.1353 s\n","loss: 0.8546 (epoch: 30, step: 150) // Avg time/img: 0.1343 s\n","loss: 0.8529 (epoch: 30, step: 200) // Avg time/img: 0.1341 s\n","----- VALIDATING - EPOCH 30 -----\n","VAL loss: 1.062 (epoch: 30, step: 0) // Avg time/img: 0.0517 s\n","VAL loss: 1.611 (epoch: 30, step: 50) // Avg time/img: 0.0485 s\n","VAL loss: 1.621 (epoch: 30, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.44 (epoch: 30, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m42.67\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 30)\n","----- TRAINING - EPOCH 31 -----\n","LEARNING RATE:  0.0002679433656340733\n","loss: 0.7981 (epoch: 31, step: 0) // Avg time/img: 0.1629 s\n","loss: 0.8469 (epoch: 31, step: 50) // Avg time/img: 0.1384 s\n","loss: 0.8559 (epoch: 31, step: 100) // Avg time/img: 0.1358 s\n","loss: 0.8588 (epoch: 31, step: 150) // Avg time/img: 0.1349 s\n","loss: 0.8606 (epoch: 31, step: 200) // Avg time/img: 0.1344 s\n","----- VALIDATING - EPOCH 31 -----\n","VAL loss: 1.106 (epoch: 31, step: 0) // Avg time/img: 0.0493 s\n","VAL loss: 1.512 (epoch: 31, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.488 (epoch: 31, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.324 (epoch: 31, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m44.16\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 31)\n","----- TRAINING - EPOCH 32 -----\n","LEARNING RATE:  0.0002598915008274931\n","loss: 0.7839 (epoch: 32, step: 0) // Avg time/img: 0.1602 s\n","loss: 0.7762 (epoch: 32, step: 50) // Avg time/img: 0.1358 s\n","loss: 0.8183 (epoch: 32, step: 100) // Avg time/img: 0.1360 s\n","loss: 0.8214 (epoch: 32, step: 150) // Avg time/img: 0.1351 s\n","loss: 0.8032 (epoch: 32, step: 200) // Avg time/img: 0.1346 s\n","----- VALIDATING - EPOCH 32 -----\n","VAL loss: 1.071 (epoch: 32, step: 0) // Avg time/img: 0.0459 s\n","VAL loss: 1.594 (epoch: 32, step: 50) // Avg time/img: 0.0476 s\n","VAL loss: 1.619 (epoch: 32, step: 100) // Avg time/img: 0.0474 s\n","VAL loss: 1.456 (epoch: 32, step: 150) // Avg time/img: 0.0475 s\n","EPOCH IoU on VAL set:  \u001b[0m43.44\u001b[0m %\n","----- TRAINING - EPOCH 33 -----\n","LEARNING RATE:  0.00025181181724366923\n","loss: 1.669 (epoch: 33, step: 0) // Avg time/img: 0.1443 s\n","loss: 0.8055 (epoch: 33, step: 50) // Avg time/img: 0.1358 s\n","loss: 0.807 (epoch: 33, step: 100) // Avg time/img: 0.1357 s\n","loss: 0.8118 (epoch: 33, step: 150) // Avg time/img: 0.1348 s\n","loss: 0.8127 (epoch: 33, step: 200) // Avg time/img: 0.1344 s\n","----- VALIDATING - EPOCH 33 -----\n","VAL loss: 1.053 (epoch: 33, step: 0) // Avg time/img: 0.0538 s\n","VAL loss: 1.617 (epoch: 33, step: 50) // Avg time/img: 0.0485 s\n","VAL loss: 1.658 (epoch: 33, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.482 (epoch: 33, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m43.02\u001b[0m %\n","----- TRAINING - EPOCH 34 -----\n","LEARNING RATE:  0.00024370321958949772\n","loss: 0.6706 (epoch: 34, step: 0) // Avg time/img: 0.1431 s\n","loss: 0.8039 (epoch: 34, step: 50) // Avg time/img: 0.1354 s\n","loss: 0.7864 (epoch: 34, step: 100) // Avg time/img: 0.1344 s\n","loss: 0.8017 (epoch: 34, step: 150) // Avg time/img: 0.1348 s\n","loss: 0.7923 (epoch: 34, step: 200) // Avg time/img: 0.1344 s\n","----- VALIDATING - EPOCH 34 -----\n","VAL loss: 1.186 (epoch: 34, step: 0) // Avg time/img: 0.0501 s\n","VAL loss: 1.655 (epoch: 34, step: 50) // Avg time/img: 0.0490 s\n","VAL loss: 1.757 (epoch: 34, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.595 (epoch: 34, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m41.95\u001b[0m %\n","----- TRAINING - EPOCH 35 -----\n","LEARNING RATE:  0.00023556452716873652\n","loss: 1.243 (epoch: 35, step: 0) // Avg time/img: 0.1412 s\n","loss: 0.8962 (epoch: 35, step: 50) // Avg time/img: 0.1355 s\n","loss: 0.8485 (epoch: 35, step: 100) // Avg time/img: 0.1341 s\n","loss: 0.8212 (epoch: 35, step: 150) // Avg time/img: 0.1347 s\n","loss: 0.8234 (epoch: 35, step: 200) // Avg time/img: 0.1342 s\n","----- VALIDATING - EPOCH 35 -----\n","VAL loss: 1.34 (epoch: 35, step: 0) // Avg time/img: 0.0510 s\n","VAL loss: 1.808 (epoch: 35, step: 50) // Avg time/img: 0.0484 s\n","VAL loss: 1.905 (epoch: 35, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.695 (epoch: 35, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m42.09\u001b[0m %\n","----- TRAINING - EPOCH 36 -----\n","LEARNING RATE:  0.00022739446367039517\n","loss: 0.6884 (epoch: 36, step: 0) // Avg time/img: 0.1386 s\n","loss: 0.807 (epoch: 36, step: 50) // Avg time/img: 0.1355 s\n","loss: 0.7951 (epoch: 36, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.7958 (epoch: 36, step: 150) // Avg time/img: 0.1335 s\n","loss: 0.7812 (epoch: 36, step: 200) // Avg time/img: 0.1343 s\n","----- VALIDATING - EPOCH 36 -----\n","VAL loss: 0.9757 (epoch: 36, step: 0) // Avg time/img: 0.0583 s\n","VAL loss: 1.476 (epoch: 36, step: 50) // Avg time/img: 0.0483 s\n","VAL loss: 1.515 (epoch: 36, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.37 (epoch: 36, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m44.95\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 36)\n","----- TRAINING - EPOCH 37 -----\n","LEARNING RATE:  0.00021919164527704348\n","loss: 0.6 (epoch: 37, step: 0) // Avg time/img: 0.1627 s\n","loss: 0.7065 (epoch: 37, step: 50) // Avg time/img: 0.1361 s\n","loss: 0.728 (epoch: 37, step: 100) // Avg time/img: 0.1348 s\n","loss: 0.7455 (epoch: 37, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.7648 (epoch: 37, step: 200) // Avg time/img: 0.1347 s\n","----- VALIDATING - EPOCH 37 -----\n","VAL loss: 1.034 (epoch: 37, step: 0) // Avg time/img: 0.0528 s\n","VAL loss: 1.55 (epoch: 37, step: 50) // Avg time/img: 0.0483 s\n","VAL loss: 1.592 (epoch: 37, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.421 (epoch: 37, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m43.44\u001b[0m %\n","----- TRAINING - EPOCH 38 -----\n","LEARNING RATE:  0.00021095456673472888\n","loss: 0.5704 (epoch: 38, step: 0) // Avg time/img: 0.1343 s\n","loss: 0.7474 (epoch: 38, step: 50) // Avg time/img: 0.1351 s\n","loss: 0.7447 (epoch: 38, step: 100) // Avg time/img: 0.1341 s\n","loss: 0.7479 (epoch: 38, step: 150) // Avg time/img: 0.1336 s\n","loss: 0.7568 (epoch: 38, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 38 -----\n","VAL loss: 1.0 (epoch: 38, step: 0) // Avg time/img: 0.0461 s\n","VAL loss: 1.576 (epoch: 38, step: 50) // Avg time/img: 0.0484 s\n","VAL loss: 1.633 (epoch: 38, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.457 (epoch: 38, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m44.44\u001b[0m %\n","----- TRAINING - EPOCH 39 -----\n","LEARNING RATE:  0.0002026815849307756\n","loss: 0.8828 (epoch: 39, step: 0) // Avg time/img: 0.1386 s\n","loss: 0.7392 (epoch: 39, step: 50) // Avg time/img: 0.1353 s\n","loss: 0.738 (epoch: 39, step: 100) // Avg time/img: 0.1341 s\n","loss: 0.7403 (epoch: 39, step: 150) // Avg time/img: 0.1336 s\n","loss: 0.7376 (epoch: 39, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 39 -----\n","VAL loss: 1.06 (epoch: 39, step: 0) // Avg time/img: 0.0510 s\n","VAL loss: 1.577 (epoch: 39, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.648 (epoch: 39, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.48 (epoch: 39, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m44.42\u001b[0m %\n","----- TRAINING - EPOCH 40 -----\n","LEARNING RATE:  0.00019437089939938174\n","loss: 0.8675 (epoch: 40, step: 0) // Avg time/img: 0.1436 s\n","loss: 0.7069 (epoch: 40, step: 50) // Avg time/img: 0.1352 s\n","loss: 0.7006 (epoch: 40, step: 100) // Avg time/img: 0.1345 s\n","loss: 0.7089 (epoch: 40, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.7224 (epoch: 40, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 40 -----\n","VAL loss: 1.122 (epoch: 40, step: 0) // Avg time/img: 0.0495 s\n","VAL loss: 1.589 (epoch: 40, step: 50) // Avg time/img: 0.0488 s\n","VAL loss: 1.62 (epoch: 40, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.433 (epoch: 40, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m43.88\u001b[0m %\n","----- TRAINING - EPOCH 41 -----\n","LEARNING RATE:  0.00018602052900565077\n","loss: 0.6026 (epoch: 41, step: 0) // Avg time/img: 0.1605 s\n","loss: 0.7241 (epoch: 41, step: 50) // Avg time/img: 0.1348 s\n","loss: 0.7152 (epoch: 41, step: 100) // Avg time/img: 0.1338 s\n","loss: 0.7204 (epoch: 41, step: 150) // Avg time/img: 0.1334 s\n","loss: 0.7223 (epoch: 41, step: 200) // Avg time/img: 0.1334 s\n","----- VALIDATING - EPOCH 41 -----\n","VAL loss: 1.113 (epoch: 41, step: 0) // Avg time/img: 0.0513 s\n","VAL loss: 1.539 (epoch: 41, step: 50) // Avg time/img: 0.0479 s\n","VAL loss: 1.552 (epoch: 41, step: 100) // Avg time/img: 0.0476 s\n","VAL loss: 1.375 (epoch: 41, step: 150) // Avg time/img: 0.0476 s\n","EPOCH IoU on VAL set:  \u001b[0m45.29\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 41)\n","----- TRAINING - EPOCH 42 -----\n","LEARNING RATE:  0.00017762828382899407\n","loss: 0.5565 (epoch: 42, step: 0) // Avg time/img: 0.1618 s\n","loss: 0.7047 (epoch: 42, step: 50) // Avg time/img: 0.1360 s\n","loss: 0.73 (epoch: 42, step: 100) // Avg time/img: 0.1345 s\n","loss: 0.7214 (epoch: 42, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.7081 (epoch: 42, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 42 -----\n","VAL loss: 0.9392 (epoch: 42, step: 0) // Avg time/img: 0.0483 s\n","VAL loss: 1.414 (epoch: 42, step: 50) // Avg time/img: 0.0490 s\n","VAL loss: 1.46 (epoch: 42, step: 100) // Avg time/img: 0.0484 s\n","VAL loss: 1.308 (epoch: 42, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m45.72\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 42)\n","----- TRAINING - EPOCH 43 -----\n","LEARNING RATE:  0.00016919173095082495\n","loss: 0.7759 (epoch: 43, step: 0) // Avg time/img: 0.1711 s\n","loss: 0.7225 (epoch: 43, step: 50) // Avg time/img: 0.1359 s\n","loss: 0.7255 (epoch: 43, step: 100) // Avg time/img: 0.1343 s\n","loss: 0.7271 (epoch: 43, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.721 (epoch: 43, step: 200) // Avg time/img: 0.1338 s\n","----- VALIDATING - EPOCH 43 -----\n","VAL loss: 1.072 (epoch: 43, step: 0) // Avg time/img: 0.0523 s\n","VAL loss: 1.426 (epoch: 43, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 1.463 (epoch: 43, step: 100) // Avg time/img: 0.0477 s\n","VAL loss: 1.317 (epoch: 43, step: 150) // Avg time/img: 0.0476 s\n","EPOCH IoU on VAL set:  \u001b[0m45.84\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 43)\n","----- TRAINING - EPOCH 44 -----\n","LEARNING RATE:  0.0001607081524100206\n","loss: 1.323 (epoch: 44, step: 0) // Avg time/img: 0.1656 s\n","loss: 0.6817 (epoch: 44, step: 50) // Avg time/img: 0.1362 s\n","loss: 0.6927 (epoch: 44, step: 100) // Avg time/img: 0.1345 s\n","loss: 0.6845 (epoch: 44, step: 150) // Avg time/img: 0.1338 s\n","loss: 0.69 (epoch: 44, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 44 -----\n","VAL loss: 1.231 (epoch: 44, step: 0) // Avg time/img: 0.0510 s\n","VAL loss: 1.677 (epoch: 44, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 1.791 (epoch: 44, step: 100) // Avg time/img: 0.0477 s\n","VAL loss: 1.607 (epoch: 44, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m43.64\u001b[0m %\n","----- TRAINING - EPOCH 45 -----\n","LEARNING RATE:  0.00015217449296258857\n","loss: 0.5533 (epoch: 45, step: 0) // Avg time/img: 0.1512 s\n","loss: 0.6741 (epoch: 45, step: 50) // Avg time/img: 0.1359 s\n","loss: 0.6836 (epoch: 45, step: 100) // Avg time/img: 0.1343 s\n","loss: 0.6819 (epoch: 45, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.6906 (epoch: 45, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 45 -----\n","VAL loss: 1.579 (epoch: 45, step: 0) // Avg time/img: 0.0455 s\n","VAL loss: 1.647 (epoch: 45, step: 50) // Avg time/img: 0.0480 s\n","VAL loss: 1.715 (epoch: 45, step: 100) // Avg time/img: 0.0477 s\n","VAL loss: 1.545 (epoch: 45, step: 150) // Avg time/img: 0.0476 s\n","EPOCH IoU on VAL set:  \u001b[0m43.47\u001b[0m %\n","----- TRAINING - EPOCH 46 -----\n","LEARNING RATE:  0.00014358729437462936\n","loss: 0.6113 (epoch: 46, step: 0) // Avg time/img: 0.1655 s\n","loss: 0.6398 (epoch: 46, step: 50) // Avg time/img: 0.1357 s\n","loss: 0.6647 (epoch: 46, step: 100) // Avg time/img: 0.1341 s\n","loss: 0.6695 (epoch: 46, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.6712 (epoch: 46, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 46 -----\n","VAL loss: 1.302 (epoch: 46, step: 0) // Avg time/img: 0.0556 s\n","VAL loss: 1.671 (epoch: 46, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.755 (epoch: 46, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.568 (epoch: 46, step: 150) // Avg time/img: 0.0476 s\n","EPOCH IoU on VAL set:  \u001b[0m44.33\u001b[0m %\n","----- TRAINING - EPOCH 47 -----\n","LEARNING RATE:  0.00013494261163740181\n","loss: 0.6396 (epoch: 47, step: 0) // Avg time/img: 0.1544 s\n","loss: 0.6756 (epoch: 47, step: 50) // Avg time/img: 0.1349 s\n","loss: 0.6756 (epoch: 47, step: 100) // Avg time/img: 0.1339 s\n","loss: 0.6698 (epoch: 47, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.6672 (epoch: 47, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 47 -----\n","VAL loss: 1.076 (epoch: 47, step: 0) // Avg time/img: 0.0556 s\n","VAL loss: 1.483 (epoch: 47, step: 50) // Avg time/img: 0.0478 s\n","VAL loss: 1.534 (epoch: 47, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.369 (epoch: 47, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m45.55\u001b[0m %\n","----- TRAINING - EPOCH 48 -----\n","LEARNING RATE:  0.00012623590446718072\n","loss: 0.5071 (epoch: 48, step: 0) // Avg time/img: 0.1456 s\n","loss: 0.6101 (epoch: 48, step: 50) // Avg time/img: 0.1358 s\n","loss: 0.6481 (epoch: 48, step: 100) // Avg time/img: 0.1343 s\n","loss: 0.6534 (epoch: 48, step: 150) // Avg time/img: 0.1338 s\n","loss: 0.6549 (epoch: 48, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 48 -----\n","VAL loss: 1.124 (epoch: 48, step: 0) // Avg time/img: 0.0555 s\n","VAL loss: 1.607 (epoch: 48, step: 50) // Avg time/img: 0.0488 s\n","VAL loss: 1.682 (epoch: 48, step: 100) // Avg time/img: 0.0485 s\n","VAL loss: 1.516 (epoch: 48, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m44.11\u001b[0m %\n","----- TRAINING - EPOCH 49 -----\n","LEARNING RATE:  0.00011746189430880188\n","loss: 1.23 (epoch: 49, step: 0) // Avg time/img: 0.1672 s\n","loss: 0.6812 (epoch: 49, step: 50) // Avg time/img: 0.1359 s\n","loss: 0.6601 (epoch: 49, step: 100) // Avg time/img: 0.1342 s\n","loss: 0.6659 (epoch: 49, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.6558 (epoch: 49, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 49 -----\n","VAL loss: 1.017 (epoch: 49, step: 0) // Avg time/img: 0.0519 s\n","VAL loss: 1.452 (epoch: 49, step: 50) // Avg time/img: 0.0486 s\n","VAL loss: 1.486 (epoch: 49, step: 100) // Avg time/img: 0.0479 s\n","VAL loss: 1.324 (epoch: 49, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m46.22\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 49)\n","----- TRAINING - EPOCH 50 -----\n","LEARNING RATE:  0.00010861437203680056\n","loss: 0.6738 (epoch: 50, step: 0) // Avg time/img: 0.1730 s\n","loss: 0.6223 (epoch: 50, step: 50) // Avg time/img: 0.1352 s\n","loss: 0.6403 (epoch: 50, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.6523 (epoch: 50, step: 150) // Avg time/img: 0.1334 s\n","loss: 0.6472 (epoch: 50, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 50 -----\n","VAL loss: 0.999 (epoch: 50, step: 0) // Avg time/img: 0.0534 s\n","VAL loss: 1.43 (epoch: 50, step: 50) // Avg time/img: 0.0479 s\n","VAL loss: 1.472 (epoch: 50, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.313 (epoch: 50, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m46.35\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 50)\n","----- TRAINING - EPOCH 51 -----\n","LEARNING RATE:  9.96859332376096e-05\n","loss: 0.5942 (epoch: 51, step: 0) // Avg time/img: 0.1628 s\n","loss: 0.6536 (epoch: 51, step: 50) // Avg time/img: 0.1357 s\n","loss: 0.6508 (epoch: 51, step: 100) // Avg time/img: 0.1342 s\n","loss: 0.6449 (epoch: 51, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.6443 (epoch: 51, step: 200) // Avg time/img: 0.1336 s\n","----- VALIDATING - EPOCH 51 -----\n","VAL loss: 1.034 (epoch: 51, step: 0) // Avg time/img: 0.0480 s\n","VAL loss: 1.478 (epoch: 51, step: 50) // Avg time/img: 0.0484 s\n","VAL loss: 1.527 (epoch: 51, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.371 (epoch: 51, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m45.80\u001b[0m %\n","----- TRAINING - EPOCH 52 -----\n","LEARNING RATE:  9.066760365683728e-05\n","loss: 0.5034 (epoch: 52, step: 0) // Avg time/img: 0.1427 s\n","loss: 0.6309 (epoch: 52, step: 50) // Avg time/img: 0.1360 s\n","loss: 0.6512 (epoch: 52, step: 100) // Avg time/img: 0.1344 s\n","loss: 0.6466 (epoch: 52, step: 150) // Avg time/img: 0.1338 s\n","loss: 0.6433 (epoch: 52, step: 200) // Avg time/img: 0.1338 s\n","----- VALIDATING - EPOCH 52 -----\n","VAL loss: 1.051 (epoch: 52, step: 0) // Avg time/img: 0.0512 s\n","VAL loss: 1.424 (epoch: 52, step: 50) // Avg time/img: 0.0486 s\n","VAL loss: 1.47 (epoch: 52, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.314 (epoch: 52, step: 150) // Avg time/img: 0.0477 s\n","EPOCH IoU on VAL set:  \u001b[0m46.43\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 52)\n","----- TRAINING - EPOCH 53 -----\n","LEARNING RATE:  8.154829161610912e-05\n","loss: 0.4996 (epoch: 53, step: 0) // Avg time/img: 0.1578 s\n","loss: 0.6411 (epoch: 53, step: 50) // Avg time/img: 0.1355 s\n","loss: 0.6483 (epoch: 53, step: 100) // Avg time/img: 0.1340 s\n","loss: 0.6388 (epoch: 53, step: 150) // Avg time/img: 0.1337 s\n","loss: 0.638 (epoch: 53, step: 200) // Avg time/img: 0.1335 s\n","----- VALIDATING - EPOCH 53 -----\n","VAL loss: 1.145 (epoch: 53, step: 0) // Avg time/img: 0.0567 s\n","VAL loss: 1.504 (epoch: 53, step: 50) // Avg time/img: 0.0483 s\n","VAL loss: 1.543 (epoch: 53, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.358 (epoch: 53, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m45.14\u001b[0m %\n","----- TRAINING - EPOCH 54 -----\n","LEARNING RATE:  7.231395505915424e-05\n","loss: 0.5379 (epoch: 54, step: 0) // Avg time/img: 0.1654 s\n","loss: 0.6524 (epoch: 54, step: 50) // Avg time/img: 0.1357 s\n","loss: 0.6382 (epoch: 54, step: 100) // Avg time/img: 0.1343 s\n","loss: 0.6259 (epoch: 54, step: 150) // Avg time/img: 0.1340 s\n","loss: 0.6341 (epoch: 54, step: 200) // Avg time/img: 0.1338 s\n","----- VALIDATING - EPOCH 54 -----\n","VAL loss: 1.081 (epoch: 54, step: 0) // Avg time/img: 0.0531 s\n","VAL loss: 1.45 (epoch: 54, step: 50) // Avg time/img: 0.0481 s\n","VAL loss: 1.483 (epoch: 54, step: 100) // Avg time/img: 0.0478 s\n","VAL loss: 1.317 (epoch: 54, step: 150) // Avg time/img: 0.0478 s\n","EPOCH IoU on VAL set:  \u001b[0m46.19\u001b[0m %\n","----- TRAINING - EPOCH 55 -----\n","LEARNING RATE:  6.294627058970836e-05\n","loss: 0.5893 (epoch: 55, step: 0) // Avg time/img: 0.1416 s\n","loss: 0.6274 (epoch: 55, step: 50) // Avg time/img: 0.1352 s\n","loss: 0.647 (epoch: 55, step: 100) // Avg time/img: 0.1344 s\n","loss: 0.6359 (epoch: 55, step: 150) // Avg time/img: 0.1341 s\n","loss: 0.6233 (epoch: 55, step: 200) // Avg time/img: 0.1338 s\n","----- VALIDATING - EPOCH 55 -----\n","VAL loss: 1.023 (epoch: 55, step: 0) // Avg time/img: 0.0478 s\n","VAL loss: 1.437 (epoch: 55, step: 50) // Avg time/img: 0.0487 s\n","VAL loss: 1.486 (epoch: 55, step: 100) // Avg time/img: 0.0484 s\n","VAL loss: 1.324 (epoch: 55, step: 150) // Avg time/img: 0.0483 s\n","EPOCH IoU on VAL set:  \u001b[0m46.32\u001b[0m %\n","----- TRAINING - EPOCH 56 -----\n","LEARNING RATE:  5.3420368916117334e-05\n","loss: 0.5383 (epoch: 56, step: 0) // Avg time/img: 0.1539 s\n","loss: 0.6192 (epoch: 56, step: 50) // Avg time/img: 0.1359 s\n","loss: 0.6286 (epoch: 56, step: 100) // Avg time/img: 0.1345 s\n","loss: 0.6152 (epoch: 56, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.622 (epoch: 56, step: 200) // Avg time/img: 0.1339 s\n","----- VALIDATING - EPOCH 56 -----\n","VAL loss: 1.088 (epoch: 56, step: 0) // Avg time/img: 0.0541 s\n","VAL loss: 1.488 (epoch: 56, step: 50) // Avg time/img: 0.0476 s\n","VAL loss: 1.533 (epoch: 56, step: 100) // Avg time/img: 0.0477 s\n","VAL loss: 1.366 (epoch: 56, step: 150) // Avg time/img: 0.0476 s\n","EPOCH IoU on VAL set:  \u001b[0m45.65\u001b[0m %\n","----- TRAINING - EPOCH 57 -----\n","LEARNING RATE:  4.370064743465832e-05\n","loss: 0.5716 (epoch: 57, step: 0) // Avg time/img: 0.1566 s\n","loss: 0.5857 (epoch: 57, step: 50) // Avg time/img: 0.1356 s\n","loss: 0.6047 (epoch: 57, step: 100) // Avg time/img: 0.1346 s\n","loss: 0.6217 (epoch: 57, step: 150) // Avg time/img: 0.1341 s\n","loss: 0.6167 (epoch: 57, step: 200) // Avg time/img: 0.1339 s\n","----- VALIDATING - EPOCH 57 -----\n","VAL loss: 1.076 (epoch: 57, step: 0) // Avg time/img: 0.0602 s\n","VAL loss: 1.471 (epoch: 57, step: 50) // Avg time/img: 0.0487 s\n","VAL loss: 1.516 (epoch: 57, step: 100) // Avg time/img: 0.0482 s\n","VAL loss: 1.35 (epoch: 57, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m45.68\u001b[0m %\n","----- TRAINING - EPOCH 58 -----\n","LEARNING RATE:  3.373207119183911e-05\n","loss: 0.5574 (epoch: 58, step: 0) // Avg time/img: 0.1561 s\n","loss: 0.6467 (epoch: 58, step: 50) // Avg time/img: 0.1359 s\n","loss: 0.6239 (epoch: 58, step: 100) // Avg time/img: 0.1346 s\n","loss: 0.6204 (epoch: 58, step: 150) // Avg time/img: 0.1340 s\n","loss: 0.6071 (epoch: 58, step: 200) // Avg time/img: 0.1340 s\n","----- VALIDATING - EPOCH 58 -----\n","VAL loss: 1.098 (epoch: 58, step: 0) // Avg time/img: 0.0522 s\n","VAL loss: 1.449 (epoch: 58, step: 50) // Avg time/img: 0.0486 s\n","VAL loss: 1.494 (epoch: 58, step: 100) // Avg time/img: 0.0480 s\n","VAL loss: 1.337 (epoch: 58, step: 150) // Avg time/img: 0.0481 s\n","EPOCH IoU on VAL set:  \u001b[0m46.27\u001b[0m %\n","----- TRAINING - EPOCH 59 -----\n","LEARNING RATE:  2.3418597108060762e-05\n","loss: 0.5641 (epoch: 59, step: 0) // Avg time/img: 0.1600 s\n","loss: 0.6198 (epoch: 59, step: 50) // Avg time/img: 0.1356 s\n","loss: 0.6103 (epoch: 59, step: 100) // Avg time/img: 0.1345 s\n","loss: 0.6062 (epoch: 59, step: 150) // Avg time/img: 0.1343 s\n","loss: 0.6091 (epoch: 59, step: 200) // Avg time/img: 0.1342 s\n","----- VALIDATING - EPOCH 59 -----\n","VAL loss: 1.011 (epoch: 59, step: 0) // Avg time/img: 0.0523 s\n","VAL loss: 1.412 (epoch: 59, step: 50) // Avg time/img: 0.0482 s\n","VAL loss: 1.448 (epoch: 59, step: 100) // Avg time/img: 0.0481 s\n","VAL loss: 1.292 (epoch: 59, step: 150) // Avg time/img: 0.0482 s\n","EPOCH IoU on VAL set:  \u001b[0m47.17\u001b[0m %\n","Saving model as best\n","save: /content/gdrive/MyDrive/Colab Notebooks/erf-KD/model_best.pth (epoch: 59)\n","----- TRAINING - EPOCH 60 -----\n","LEARNING RATE:  1.254971545512439e-05\n","loss: 0.6026 (epoch: 60, step: 0) // Avg time/img: 0.1540 s\n","loss: 0.6132 (epoch: 60, step: 50) // Avg time/img: 0.1358 s\n","loss: 0.6162 (epoch: 60, step: 100) // Avg time/img: 0.1347 s\n","loss: 0.6025 (epoch: 60, step: 150) // Avg time/img: 0.1339 s\n","loss: 0.5958 (epoch: 60, step: 200) // Avg time/img: 0.1337 s\n","----- VALIDATING - EPOCH 60 -----\n","VAL loss: 0.9723 (epoch: 60, step: 0) // Avg time/img: 0.0541 s\n","VAL loss: 1.382 (epoch: 60, step: 50) // Avg time/img: 0.0488 s\n","VAL loss: 1.406 (epoch: 60, step: 100) // Avg time/img: 0.0482 s\n","VAL loss: 1.257 (epoch: 60, step: 150) // Avg time/img: 0.0479 s\n","EPOCH IoU on VAL set:  \u001b[0m47.14\u001b[0m %\n","========== TRAINING FINISHED ===========\n"]}],"source":["import os\n","import random\n","import time\n","import numpy as np\n","import torch\n","import math\n","import warnings\n","\n","from PIL import Image, ImageOps\n","from argparse import ArgumentParser\n","\n","from torch.optim import SGD, Adam, lr_scheduler\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import Compose, CenterCrop, Normalize, Resize, Pad\n","from torchvision.transforms import ToTensor, ToPILImage\n","\n","import importlib\n","\n","from shutil import copyfile\n","\n","\n","warnings.filterwarnings(action='ignore')\n","\n","NUM_CHANNELS = 3\n","NUM_CLASSES = 20 #pascal=22, cityscapes=20\n","\n","color_transform = Colorize(NUM_CLASSES)\n","image_transform = ToPILImage()\n","\n","#Augmentations - different function implemented to perform random augments on both image and target\n","class MyCoTransform(object):\n","    def __init__(self, enc, augment=True, height=512):\n","        self.enc=enc\n","        self.augment = augment\n","        self.height = height\n","        pass\n","    def __call__(self, input, target):\n","        # do something to both images\n","        input =  Resize(self.height, Image.BILINEAR)(input)\n","        target = Resize(self.height, Image.NEAREST)(target)\n","\n","        if(self.augment):\n","            # Random hflip\n","            hflip = random.random()\n","            if (hflip < 0.5):\n","                input = input.transpose(Image.FLIP_LEFT_RIGHT)\n","                target = target.transpose(Image.FLIP_LEFT_RIGHT)\n","            \n","            #Random translation 0-2 pixels (fill rest with padding\n","            transX = random.randint(-2, 2) \n","            transY = random.randint(-2, 2)\n","\n","            input = ImageOps.expand(input, border=(transX,transY,0,0), fill=0)\n","            target = ImageOps.expand(target, border=(transX,transY,0,0), fill=255) #pad label filling with 255\n","            input = input.crop((0, 0, input.size[0]-transX, input.size[1]-transY))\n","            target = target.crop((0, 0, target.size[0]-transX, target.size[1]-transY))   \n","\n","        input = ToTensor()(input)\n","        if (self.enc):\n","            target = Resize(int(self.height/8), Image.NEAREST)(target)\n","        target = ToLabel()(target)\n","        target = Relabel(255, 19)(target)\n","\n","        return input, target\n","\n","class MainLoss(torch.nn.Module):\n","    def __init__(self, weight=None):\n","      super().__init__()\n","      self.celoss = torch.nn.NLLLoss2d(weight) # CrossEntropyLoss2d\n","      # self.kdloss = torch.nn.KLDivLoss(reduction='batchmean')\n","      self.kdloss = torch.nn.MSELoss()\n","    \n","    def forward(self, outputs, targets, toutputs):\n","      T = 4 # Temperature\n","      alpha = 0.5 # alpha\n","\n","      # 기본 Loss\n","      general_loss = self.celoss(torch.nn.functional.log_softmax(outputs, dim=1), targets)\n","\n","      # KD Loss\n","      # toutputs[0].detach()\n","      # kd_loss = self.kdloss(F.log_softmax(outputs[0] / T, dim=1), F.softmax(toutputs[0] / T, dim=1)) * (T*T)\n","      # kd_loss = self.kdloss(F.log_softmax(outputs / T, dim=1), F.softmax(toutputs / T, dim=1)) * (T*T)\n","      kd_loss = self.kdloss(outputs / T, toutputs / T) * (T*T)\n","\n","      # Loss\n","      loss = alpha * general_loss + (1-alpha) * kd_loss\n","      return loss\n","\n","\n","def train(args, tmodel, model, enc=False):\n","    best_acc = 0\n","\n","    #TODO: calculate weights by processing dataset histogram (now its being set by hand from the torch values)\n","    #create a loder to run all images and calculate histogram of labels, then create weight array using class balancing\n","\n","    weight = torch.ones(NUM_CLASSES)\n","    if (enc):\n","        weight[0] = 2.3653597831726\t\n","        weight[1] = 4.4237880706787\t\n","        weight[2] = 2.9691488742828\t\n","        weight[3] = 5.3442072868347\t\n","        weight[4] = 5.2983593940735\t\n","        weight[5] = 5.2275490760803\t\n","        weight[6] = 5.4394111633301\t\n","        weight[7] = 5.3659925460815\t\n","        weight[8] = 3.4170460700989\t\n","        weight[9] = 5.2414722442627\t\n","        weight[10] = 4.7376127243042\t\n","        weight[11] = 5.2286224365234\t\n","        weight[12] = 5.455126285553\t\n","        weight[13] = 4.3019247055054\t\n","        weight[14] = 5.4264230728149\t\n","        weight[15] = 5.4331531524658\t\n","        weight[16] = 5.433765411377\t\n","        weight[17] = 5.4631009101868\t\n","        weight[18] = 5.3947434425354\n","    else:\n","        weight[0] = 2.8149201869965\t\n","        weight[1] = 6.9850029945374\t\n","        weight[2] = 3.7890393733978\t\n","        weight[3] = 9.9428062438965\t\n","        weight[4] = 9.7702074050903\t\n","        weight[5] = 9.5110931396484\t\n","        weight[6] = 10.311357498169\t\n","        weight[7] = 10.026463508606\t\n","        weight[8] = 4.6323022842407\t\n","        weight[9] = 9.5608062744141\t\n","        weight[10] = 7.8698215484619\t\n","        weight[11] = 9.5168733596802\t\n","        weight[12] = 10.373730659485\t\n","        weight[13] = 6.6616044044495\t\n","        weight[14] = 10.260489463806\t\n","        weight[15] = 10.287888526917\t\n","        weight[16] = 10.289801597595\t\n","        weight[17] = 10.405355453491\t\n","        weight[18] = 10.138095855713\t\n","\n","    weight[19] = 0\n","\n","    # assert os.path.exists(args.datadir), \"Error: datadir (dataset directory) could not be loaded\"\n","\n","    co_transform = MyCoTransform(enc, augment=True, height=args.height)#1024)\n","    co_transform_val = MyCoTransform(enc, augment=False, height=args.height)#1024)\n","    dataset_train = cityscapes(args.datadir, co_transform, 'train')\n","    dataset_val = cityscapes(args.datadir, co_transform_val, 'val')\n","\n","    loader = DataLoader(dataset_train, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=True)\n","    loader_val = DataLoader(dataset_val, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n","\n","    if args.cuda:\n","        weight = weight.cuda()\n","    criterion = MainLoss(weight) # Loss 변경부분\n","    print(type(criterion))\n","\n","    savedir = f'{args.savedir}'\n","    \n","    if (enc):\n","        automated_log_path = savedir + \"/automated_log_encoder.txt\"\n","        modeltxtpath = savedir + \"/model_encoder.txt\"\n","    else:\n","        automated_log_path = savedir + \"/automated_log.txt\"\n","        modeltxtpath = savedir + \"/model.txt\"    \n","    \n","    if (not os.path.exists(automated_log_path)):    #dont add first line if it exists \n","        with open(automated_log_path, \"a\") as myfile:\n","            myfile.write(\"Epoch\\t\\tTrain-loss\\t\\tTest-loss\\t\\tTrain-IoU\\t\\tTest-IoU\\t\\tlearningRate\")\n","\n","    with open(modeltxtpath, \"w\") as myfile:\n","        myfile.write(str(model))\n","\n","\n","    #TODO: reduce memory in first gpu: https://discuss.pytorch.org/t/multi-gpu-training-memory-usage-in-balance/4163/4        #https://github.com/pytorch/pytorch/issues/1893\n","\n","    #optimizer = Adam(model.parameters(), 5e-4, (0.9, 0.999),  eps=1e-08, weight_decay=2e-4)     ## scheduler 1\n","    optimizer = Adam(model.parameters(), 5e-4, (0.9, 0.999),  eps=1e-08, weight_decay=1e-4)      ## scheduler 2\n","\n","    start_epoch = 1\n","    if args.resume:\n","        #Must load weights, optimizer, epoch and best value. \n","        if enc:\n","            filenameCheckpoint = savedir + '/checkpoint_enc.pth.tar'\n","        else:\n","            filenameCheckpoint = savedir + '/checkpoint.pth.tar'\n","\n","        assert os.path.exists(filenameCheckpoint), \"Error: resume option was used but checkpoint was not found in folder\"\n","        checkpoint = torch.load(filenameCheckpoint)\n","        start_epoch = checkpoint['epoch']\n","        model.load_state_dict(checkpoint['state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","        best_acc = checkpoint['best_acc']\n","        print(\"=> Loaded checkpoint at epoch {})\".format(checkpoint['epoch']))\n","\n","    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5) # set up scheduler     ## scheduler 1\n","    lambda1 = lambda epoch: pow((1-((epoch-1)/args.num_epochs)),0.9)  ## scheduler 2\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)                             ## scheduler 2\n","\n","    if args.visualize and args.steps_plot > 0:\n","        board = Dashboard(args.port)\n","\n","    for epoch in range(start_epoch, args.num_epochs+1):\n","        print(\"----- TRAINING - EPOCH\", epoch, \"-----\")\n","\n","        scheduler.step(epoch)    ## scheduler 2\n","\n","        epoch_loss = []\n","        time_train = []\n","     \n","        doIouTrain = args.iouTrain   \n","        doIouVal =  args.iouVal      \n","\n","        if (doIouTrain):\n","            iouEvalTrain = iouEval(NUM_CLASSES)\n","\n","        usedLr = 0\n","        for param_group in optimizer.param_groups:\n","            print(\"LEARNING RATE: \", param_group['lr'])\n","            usedLr = float(param_group['lr'])\n","\n","        model.train() # student model (train mode)\n","        tmodel.eval() # teacher model (eval mode)\n","        for step, (images, labels) in enumerate(loader):\n","\n","            start_time = time.time()\n","            #print (labels.size())\n","            #print (np.unique(labels.numpy()))\n","            #print(\"labels: \", np.unique(labels[0].numpy()))\n","            #labels = torch.ones(4, 1, 512, 1024).long()\n","            if args.cuda:\n","                images = images.cuda()\n","                labels = labels.cuda()\n","\n","            inputs = Variable(images)\n","            targets = Variable(labels)\n","            outputs = model(inputs, only_encode=enc)\n","            toutputs = tmodel(inputs, only_encode=enc)\n","\n","            #print(\"targets\", np.unique(targets[:, 0].cpu().data.numpy()))\n","\n","            optimizer.zero_grad()\n","            loss = criterion(outputs, targets[:, 0], toutputs) # Loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss.append(loss.item())\n","            time_train.append(time.time() - start_time)\n","\n","            if (doIouTrain):\n","                #start_time_iou = time.time()\n","                iouEvalTrain.addBatch(outputs.max(1)[1].unsqueeze(1).data, targets.data)\n","                #print (\"Time to add confusion matrix: \", time.time() - start_time_iou)      \n","\n","            #print(outputs.size())\n","            if args.visualize and args.steps_plot > 0 and step % args.steps_plot == 0:\n","                start_time_plot = time.time()\n","                image = inputs[0].cpu().data\n","                #image[0] = image[0] * .229 + .485\n","                #image[1] = image[1] * .224 + .456\n","                #image[2] = image[2] * .225 + .406\n","                #print(\"output\", np.unique(outputs[0].cpu().max(0)[1].data.numpy()))\n","                board.image(image, f'input (epoch: {epoch}, step: {step})')\n","                if isinstance(outputs, list):   #merge gpu tensors\n","                    board.image(color_transform(outputs[0][0].cpu().max(0)[1].data.unsqueeze(0)),\n","                    f'output (epoch: {epoch}, step: {step})')\n","                else:\n","                    board.image(color_transform(outputs[0].cpu().max(0)[1].data.unsqueeze(0)),\n","                    f'output (epoch: {epoch}, step: {step})')\n","                board.image(color_transform(targets[0].cpu().data),\n","                    f'target (epoch: {epoch}, step: {step})')\n","                print (\"Time to paint images: \", time.time() - start_time_plot)\n","            if args.steps_loss > 0 and step % args.steps_loss == 0:\n","                average = sum(epoch_loss) / len(epoch_loss)\n","                print(f'loss: {average:0.4} (epoch: {epoch}, step: {step})', \n","                        \"// Avg time/img: %.4f s\" % (sum(time_train) / len(time_train) / args.batch_size))\n","\n","            \n","        average_epoch_loss_train = sum(epoch_loss) / len(epoch_loss)\n","        \n","        iouTrain = 0\n","        if (doIouTrain):\n","            iouTrain, iou_classes = iouEvalTrain.getIoU()\n","            iouStr = getColorEntry(iouTrain)+'{:0.2f}'.format(iouTrain*100) + '\\033[0m'\n","            print (\"EPOCH IoU on TRAIN set: \", iouStr, \"%\")  \n","\n","        #Validate on 500 val images after each epoch of training\n","        print(\"----- VALIDATING - EPOCH\", epoch, \"-----\")\n","        model.eval()\n","        tmodel.eval()\n","        epoch_loss_val = []\n","        time_val = []\n","        \n","        if (doIouVal):\n","            iouEvalVal = iouEval(NUM_CLASSES)\n","\n","        for step, (images, labels) in enumerate(loader_val):\n","            start_time = time.time()\n","            if args.cuda:\n","                images = images.cuda()\n","                labels = labels.cuda()\n","\n","            inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n","            targets = Variable(labels, volatile=True)\n","            outputs = model(inputs, only_encode=enc) \n","            toutputs = tmodel(inputs, only_encode=enc)\n","\n","            loss = criterion(outputs, targets[:, 0], toutputs)\n","            epoch_loss_val.append(loss.item())\n","            time_val.append(time.time() - start_time)\n","\n","\n","            #Add batch to calculate TP, FP and FN for iou estimation\n","            if (doIouVal):\n","                #start_time_iou = time.time()\n","                iouEvalVal.addBatch(outputs.max(1)[1].unsqueeze(1).data, targets.data)\n","                #print (\"Time to add confusion matrix: \", time.time() - start_time_iou)\n","\n","            if args.visualize and args.steps_plot > 0 and step % args.steps_plot == 0:\n","                start_time_plot = time.time()\n","                image = inputs[0].cpu().data\n","                board.image(image, f'VAL input (epoch: {epoch}, step: {step})')\n","                if isinstance(outputs, list):   #merge gpu tensors\n","                    board.image(color_transform(outputs[0][0].cpu().max(0)[1].data.unsqueeze(0)),\n","                    f'VAL output (epoch: {epoch}, step: {step})')\n","                else:\n","                    board.image(color_transform(outputs[0].cpu().max(0)[1].data.unsqueeze(0)),\n","                    f'VAL output (epoch: {epoch}, step: {step})')\n","                board.image(color_transform(targets[0].cpu().data),\n","                    f'VAL target (epoch: {epoch}, step: {step})')\n","                print (\"Time to paint images: \", time.time() - start_time_plot)\n","            if args.steps_loss > 0 and step % args.steps_loss == 0:\n","                average = sum(epoch_loss_val) / len(epoch_loss_val)\n","                print(f'VAL loss: {average:0.4} (epoch: {epoch}, step: {step})', \n","                        \"// Avg time/img: %.4f s\" % (sum(time_val) / len(time_val) / args.batch_size))\n","                       \n","\n","        average_epoch_loss_val = sum(epoch_loss_val) / len(epoch_loss_val)\n","        #scheduler.step(average_epoch_loss_val, epoch)  ## scheduler 1   # update lr if needed\n","\n","        iouVal = 0\n","        if (doIouVal):\n","            iouVal, iou_classes = iouEvalVal.getIoU()\n","            iouStr = getColorEntry(iouVal)+'{:0.2f}'.format(iouVal*100) + '\\033[0m'\n","            print (\"EPOCH IoU on VAL set: \", iouStr, \"%\") \n","           \n","\n","        # remember best valIoU and save checkpoint\n","        if iouVal == 0:\n","            current_acc = -average_epoch_loss_val\n","        else:\n","            current_acc = iouVal \n","        is_best = current_acc > best_acc\n","        best_acc = max(current_acc, best_acc)\n","        if enc:\n","            filenameCheckpoint = savedir + '/checkpoint_enc.pth.tar'\n","            filenameBest = savedir + '/model_best_enc.pth.tar'    \n","        else:\n","            filenameCheckpoint = savedir + '/checkpoint.pth.tar'\n","            filenameBest = savedir + '/model_best.pth.tar'\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'arch': str(model),\n","            'state_dict': model.state_dict(),\n","            'best_acc': best_acc,\n","            'optimizer' : optimizer.state_dict(),\n","        }, is_best, filenameCheckpoint, filenameBest)\n","\n","        #SAVE MODEL AFTER EPOCH\n","        if (enc):\n","            filename = f'{savedir}/model_encoder-{epoch:03}.pth'\n","            filenamebest = f'{savedir}/model_encoder_best.pth'\n","        else:\n","            filename = f'{savedir}/model-{epoch:03}.pth'\n","            filenamebest = f'{savedir}/model_best.pth'\n","        if args.epochs_save > 0 and step > 0 and step % args.epochs_save == 0:\n","            torch.save(model.state_dict(), filename)\n","            print(f'save: {filename} (epoch: {epoch})')\n","        if (is_best):\n","            torch.save(model.state_dict(), filenamebest)\n","            print(f'save: {filenamebest} (epoch: {epoch})')\n","            if (not enc):\n","                with open(savedir + \"/best.txt\", \"w\") as myfile:\n","                    myfile.write(\"Best epoch is %d, with Val-IoU= %.4f\" % (epoch, iouVal))   \n","            else:\n","                with open(savedir + \"/best_encoder.txt\", \"w\") as myfile:\n","                    myfile.write(\"Best epoch is %d, with Val-IoU= %.4f\" % (epoch, iouVal))           \n","\n","        #SAVE TO FILE A ROW WITH THE EPOCH RESULT (train loss, val loss, train IoU, val IoU)\n","        #Epoch\t\tTrain-loss\t\tTest-loss\tTrain-IoU\tTest-IoU\t\tlearningRate\n","        with open(automated_log_path, \"a\") as myfile:\n","            myfile.write(\"\\n%d\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.8f\" % (epoch, average_epoch_loss_train, average_epoch_loss_val, iouTrain, iouVal, usedLr ))\n","    \n","    return(model)   #return model (convenience for encoder-decoder training)\n","\n","def save_checkpoint(state, is_best, filenameCheckpoint, filenameBest):\n","    torch.save(state, filenameCheckpoint)\n","    if is_best:\n","        print (\"Saving model as best\")\n","        torch.save(state, filenameBest)\n","\n","\n","def main(args):\n","    savedir = f'/save/{args.savedir}'\n","\n","    if not os.path.exists(savedir):\n","        os.makedirs(savedir)\n","\n","    with open(savedir + '/opts.txt', \"w\") as myfile:\n","        myfile.write(str(args))\n","\n","    #Load Teacher Model\n","    tweightspath = args.tloadDir + args.tloadWeights\n","    tmodel = TNet(NUM_CLASSES)\n","\n","    #Load Model\n","    model = Net(NUM_CLASSES)\n","    \n","    if args.cuda:\n","        tmodel = torch.nn.DataParallel(tmodel).cuda()\n","        model = torch.nn.DataParallel(model).cuda()\n","\n","    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n","        own_state = model.state_dict()\n","        for name, param in state_dict.items():\n","            if name not in own_state:\n","                 continue\n","            own_state[name].copy_(param)\n","        return model\n","\n","    tmodel = load_my_state_dict(tmodel, torch.load(tweightspath))\n","    print (\"Teacher Model and weights LOADED successfully\")\n","\n","    if args.state:\n","        #if args.state is provided then load this state for training\n","        #Note: this only loads initialized weights. If you want to resume a training use \"--resume\" option!!\n","        model = load_my_state_dict(model, torch.load(args.state))\n","\n","\n","    # train(args, tmodel, model)\n","    if (not args.decoder):\n","        print(\"========== ENCODER TRAINING ===========\")\n","        model = train(args, tmodel, model, True) #Train encoder\n","    #CAREFUL: for some reason, after training encoder alone, the decoder gets weights=0. \n","    #We must reinit decoder weights or reload network passing only encoder in order to train decoder\n","    print(\"========== DECODER TRAINING ===========\")\n","    if (not args.state):\n","        if args.pretrainedEncoder:\n","            print(\"Loading encoder pretrained in imagenet\")\n","            from erfnet_imagenet import ERFNet as ERFNet_imagenet\n","            pretrainedEnc = torch.nn.DataParallel(ERFNet_imagenet(1000))\n","            pretrainedEnc.load_state_dict(torch.load(args.pretrainedEncoder)['state_dict'])\n","            pretrainedEnc = next(pretrainedEnc.children()).features.encoder\n","            if (not args.cuda):\n","                pretrainedEnc = pretrainedEnc.cpu()     #because loaded encoder is probably saved in cuda\n","        else:\n","            pretrainedEnc = next(model.children()).encoder\n","        model = Net(NUM_CLASSES, encoder=pretrainedEnc)  #Add decoder to encoder\n","        if args.cuda:\n","            model = torch.nn.DataParallel(model).cuda()\n","        #When loading encoder reinitialize weights for decoder because they are set to 0 when training dec\n","    model = train(args, tmodel, model, False)   #Train decoder\n","    print(\"========== TRAINING FINISHED ===========\")\n","\n","if __name__ == '__main__':\n","    parser = ArgumentParser()\n","    parser.add_argument('--cuda', action='store_true', default=True)  #NOTE: cpu-only has not been tested so you might have to change code if you deactivate this flag\n","    parser.add_argument('--model', default=\"erfnet\")\n","    parser.add_argument('--state')\n","\n","    parser.add_argument('--tloadDir',default=\"/content/gdrive/MyDrive/Colab Notebooks/erf-baseline-teacher-150ep/\")\n","    parser.add_argument('--tloadWeights', default=\"model_best.pth\")\n","\n","    parser.add_argument('--port', type=int, default=8097)\n","    parser.add_argument('--datadir', default='/content/gdrive/MyDrive/Colab Notebooks/cityscapes')\n","    parser.add_argument('--height', type=int, default=512)\n","    parser.add_argument('--num-epochs', type=int, default=60)\n","    parser.add_argument('--num-workers', type=int, default=4)\n","    parser.add_argument('--batch-size', type=int, default=3)\n","    parser.add_argument('--steps-loss', type=int, default=50)\n","    parser.add_argument('--steps-plot', type=int, default=50)\n","    parser.add_argument('--epochs-save', type=int, default=0)    #You can use this value to save model every X epochs\n","    parser.add_argument('--savedir', type=str, default='/content/gdrive/MyDrive/Colab Notebooks/erf-KD')\n","    parser.add_argument('--decoder', action='store_true')\n","    parser.add_argument('--pretrainedEncoder') #, default=\"../trained_models/erfnet_encoder_pretrained.pth.tar\")\n","    parser.add_argument('--visualize', action='store_true', default=False)\n","\n","    parser.add_argument('--iouTrain', action='store_true', default=False) #recommended: False (takes more time to train otherwise)\n","    parser.add_argument('--iouVal', action='store_true', default=True)  \n","    parser.add_argument('--resume', action='store_true')    #Use this flag to load last checkpoint for training  \n","\n","    main(parser.parse_args(''))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNp489+8D3vti48jLCTBFi8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}